import os, json, numpy as np, pandas as pd, streamlit as st, altair as alt

st.set_page_config(page_title="ì¶”ì²œì œëª© ëŒ€ì‹œë³´ë“œ", layout="wide")
st.title("ì±„ë„ ê¸°ë°˜ ì¶”ì²œ ì½˜í…ì¸ ")

DATA_DIR = os.path.join(os.path.dirname(__file__), "..", "data")

# -------------------------------------------------
# ê³µìš© ìœ í‹¸
# -------------------------------------------------
def load_csv(fname):
    path = os.path.join(DATA_DIR, fname)
    return pd.read_csv(path) if os.path.exists(path) else None

def load_json(fname):
    path = os.path.join(DATA_DIR, fname)
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    return None

def first_non_none(*vals):
    for v in vals:
        if v is not None:
            return v
    return None


# -------------------------------------------------
# ë¬¸ìì—´ í˜•íƒœì˜ ìˆ˜ì¹˜(ì¡°íšŒìˆ˜/ì¢‹ì•„ìš”/ëŒ“ê¸€ ë“±)ë¥¼ floatë¡œ ë³€í™˜
#    ì˜ˆ: "12,345", "1.2ë§Œ", "3.4ì²œ", "982", "1,234íšŒ"
# -------------------------------------------------
def parse_count_series(series):
    if series is None:
        return pd.Series(dtype="float64")

    def _parse_one(x):
        if pd.isna(x):
            return np.nan
        s = str(x).strip()
        s = s.replace(",", "").replace("íšŒ", "").strip()

        # "1.2ë§Œ" -> 1.2 * 10000
        if s.endswith("ë§Œ"):
            try:
                return float(s[:-1]) * 10000
            except:
                return np.nan

        # "3.4ì²œ" -> 3.4 * 1000
        if s.endswith("ì²œ"):
            try:
                return float(s[:-1]) * 1000
            except:
                return np.nan

        # ê¸°ë³¸ ìˆ«ì
        try:
            return float(s)
        except:
            return np.nan

    return series.apply(_parse_one)


# -------------------------------------------------
# ì±„ë„ ë°ì´í„° ë¡œë” + íŒŒìƒ ì»¬ëŸ¼ ìƒì„±
#  - channel(@KoreanCryingGuy)_all_videos.csv ì‚¬ìš©
#  - ê¸°ëŒ€ ì»¬ëŸ¼:
#      title, published_date, view_count, like_count, comment_count
# -------------------------------------------------
def load_channel_df():
    ch_path = os.path.join(DATA_DIR, "channel(@KoreanCryingGuy)_all_videos.csv")
    if not os.path.exists(ch_path):
        return None

    df_ch = pd.read_csv(ch_path)

    # ì—…ë¡œë“œ ì‹œê° -> datetime
    if "published_date" in df_ch.columns:
        df_ch["_published_dt"] = pd.to_datetime(df_ch["published_date"], errors="coerce")
    else:
        df_ch["_published_dt"] = pd.NaT

    # ìˆ«ìí˜• ì§€í‘œ íŒŒì‹±
    df_ch["_views"]    = parse_count_series(df_ch["view_count"]    if "view_count"    in df_ch.columns else None)
    df_ch["_likes"]    = parse_count_series(df_ch["like_count"]    if "like_count"    in df_ch.columns else None)
    df_ch["_comments"] = parse_count_series(df_ch["comment_count"] if "comment_count" in df_ch.columns else None)

    # ë°˜ì‘ ë¹„ìœ¨
    df_ch["_like_rate"] = np.where(
        (df_ch["_views"].notna()) & (df_ch["_views"] > 0),
        df_ch["_likes"] / df_ch["_views"],
        np.nan
    )
    df_ch["_comment_rate"] = np.where(
        (df_ch["_views"].notna()) & (df_ch["_views"] > 0),
        df_ch["_comments"] / df_ch["_views"],
        np.nan
    )

    # ì—…ë¡œë“œ ìš”ì¼/ì‹œê°„
    df_ch["_dow"] = df_ch["_published_dt"].dt.dayofweek  # ì›”=0 ... ì¼=6
    df_ch["_hour"] = df_ch["_published_dt"].dt.hour      # ì—…ë¡œë“œ ì‹œê° (ì—†ìœ¼ë©´ NaN)

    return df_ch


# -------------------------------------------------
# ì±„ë„ KPI ìš”ì•½ ê³„ì‚°
# -------------------------------------------------
def build_channel_summary(df_ch: pd.DataFrame):
    """
    ë°˜í™˜ summary:
      total_videos : ì´ ì—…ë¡œë“œ ìˆ˜
      recent_30_cnt : ìµœê·¼ 30ì¼ ì—…ë¡œë“œ ìˆ˜
      avg_views_all : ì „ì²´ í‰ê·  ì¡°íšŒìˆ˜
      median_views_all : ì „ì²´ ì¤‘ì•™ê°’ ì¡°íšŒìˆ˜
      avg_views_recent5 : ìµœê·¼ 5ê°œ ì˜ìƒ í‰ê·  ì¡°íšŒìˆ˜
      avg_like_rate : í‰ê·  ì¢‹ì•„ìš”ìœ¨
      top_hits : [{'title': ì œëª©, 'views': ì¡°íšŒìˆ˜}, ...] ìƒìœ„ 3ê°œ
    """
    summary = {}

    # ì´ ì—…ë¡œë“œ ìˆ˜
    summary["total_videos"] = len(df_ch)

    # ìµœê·¼ 30ì¼ ì—…ë¡œë“œ ìˆ˜
    if df_ch["_published_dt"].notna().any():
        now = pd.Timestamp.now(tz=None)
        recent_mask = df_ch["_published_dt"] >= (now - pd.Timedelta(days=30))
        summary["recent_30_cnt"] = int(recent_mask.sum())
    else:
        summary["recent_30_cnt"] = None

    # ì¡°íšŒìˆ˜ í†µê³„
    if df_ch["_views"].notna().any():
        summary["avg_views_all"] = int(df_ch["_views"].mean())
        summary["median_views_all"] = int(df_ch["_views"].median())
    else:
        summary["avg_views_all"] = None
        summary["median_views_all"] = None

    # ìµœê·¼ 5ê°œ í‰ê·  ì¡°íšŒìˆ˜
    if df_ch["_published_dt"].notna().any():
        recent_5 = df_ch.sort_values("_published_dt", ascending=False).head(5)
    else:
        recent_5 = df_ch.tail(5)

    if recent_5["_views"].notna().any():
        summary["avg_views_recent5"] = int(recent_5["_views"].mean())
    else:
        summary["avg_views_recent5"] = None

    # ì¢‹ì•„ìš”ìœ¨ í‰ê· 
    if df_ch["_like_rate"].notna().any():
        summary["avg_like_rate"] = float(df_ch["_like_rate"].mean())
    else:
        summary["avg_like_rate"] = None

    # íˆíŠ¸ ì˜ìƒ TOP 3 (ì¡°íšŒìˆ˜ ë†’ì€ ìˆœ)
    top_hits_rows = df_ch.sort_values("_views", ascending=False).head(3)
    top_list = []
    for _, r in top_hits_rows.iterrows():
        vid_title = r.get("title", "(ì œëª© ì—†ìŒ)")
        vid_views = r.get("_views", np.nan)
        if pd.notna(vid_views):
            top_list.append({
                "title": str(vid_title),
                "views": int(vid_views),
            })
    summary["top_hits"] = top_list

    # ì•ˆì „í•˜ê²Œ í‚¤ ê¸°ë³¸ê°’ ë³´ì¥ (UIì—ì„œ KeyError ì•ˆ ë‚˜ë„ë¡)
    for k in ["avg_like_rate", "median_views_all", "avg_views_recent5"]:
        summary.setdefault(k, None)

    return summary


# -------------------------------------------------
# ë°ì´í„° ë¡œë“œ (ì¶”ì²œì œëª©/í…œí”Œë¦¿ í†µê³„ ë“±)
# -------------------------------------------------
reco      = first_non_none(load_csv("reco_results.csv"),           load_csv("reco_results_demo.csv"))
tpl_stats = first_non_none(load_csv("template_keyword_stats.csv"), load_csv("template_keyword_stats_demo.csv"))
kw_stats  = first_non_none(load_csv("keyword_stats.csv"),          load_csv("keyword_stats_demo.csv"))
feat_imp  = first_non_none(load_csv("feature_importances.csv"),    load_csv("feature_importances_demo.csv"))
p10_style = first_non_none(load_json("p10_style.json"),            load_json("p10_style_demo.json"))

if reco is None:
    st.error("reco_results.csvê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    st.stop()
    
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "analysis_mode" not in st.session_state:
    st.session_state["analysis_mode"] = False

if "idx_range" not in st.session_state:
    st.session_state["idx_range"] = None



# -------------------------------------------------
# ì‚¬ì´ë“œë°” í•„í„° (ì¡°íšŒìˆ˜ ìŠ¬ë¼ì´ë” ì œê±° ë²„ì „)
# -------------------------------------------------
with st.sidebar:
    st.header("í•„í„°")

    tpl_choices = ["(ì „ì²´)"] + sorted(reco["template"].dropna().unique().tolist())
    tpl_sel = st.selectbox("í…œí”Œë¦¿", tpl_choices)

df = reco.copy()
if tpl_sel != "(ì „ì²´)":
    df = df[df["template"] == tpl_sel]

# ìˆ«ìí™”
df["predicted_views"] = pd.to_numeric(df["predicted_views"], errors="coerce")
df = df.dropna(subset=["predicted_views"])


# -------------------------------------------------
# ì…ë ¥ í¼
# -------------------------------------------------
c1, c2 = st.columns([2, 1])
with c1:
    with st.form("predict_form"):
        title_input = st.text_input("ì±„ë„ ID", value="@KoreanCryingGuy")
        run = st.form_submit_button("ì¶”ì²œ ì œëª© ìƒì„±")

    if run:
        # ë²„íŠ¼ ëˆŒë €ìœ¼ë©´ ë¶„ì„ ëª¨ë“œ ì§„ì…
        st.session_state["analysis_mode"] = True


# -------------------------------------------------
# ì‹¤í–‰ ë²„íŠ¼ ëˆŒë €ì„ ë•Œ í™”ë©´
# -------------------------------------------------
if st.session_state["analysis_mode"]:
    ch_df = load_channel_df()

    if ch_df is not None and len(ch_df) > 0:

        # 1) ì—…ë¡œë“œ íƒ€ì„ë¼ì¸ ì •ë ¬ & ì¸ë±ìŠ¤ ë¶€ì—¬
        timeline_df = ch_df.dropna(subset=["_published_dt"]).copy()
        timeline_df = timeline_df.sort_values("_published_dt").reset_index(drop=True)
        timeline_df["_t_idx"] = timeline_df.index

        if len(timeline_df) > 0:
            min_idx = int(timeline_df["_t_idx"].min())
            max_idx = int(timeline_df["_t_idx"].max())
        else:
            min_idx = 0
            max_idx = 0
            
        with c2:    
            if len(timeline_df) > 0:
                default_start = min_idx
                default_end   = max_idx
                
                idx_range = st.slider(
                    "ë¶„ì„í•  ì—…ë¡œë“œ êµ¬ê°„",
                    min_value=min_idx,
                    max_value=max_idx,
                    value=(default_start, default_end),
                    step=1
                )
                start_idx, end_idx = idx_range

                start_dt = timeline_df.loc[timeline_df["_t_idx"] == start_idx, "_published_dt"].min()
                end_dt   = timeline_df.loc[timeline_df["_t_idx"] == end_idx,   "_published_dt"].max()
                end_dt_inclusive = end_dt + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)

                mask_in_range = (
                    (ch_df["_published_dt"].notna()) &
                    (ch_df["_published_dt"] >= start_dt) &
                    (ch_df["_published_dt"] <= end_dt_inclusive)
                )
                ch_sub = ch_df[mask_in_range].copy()

                if len(ch_sub) == 0:
                    st.warning("ì´ êµ¬ê°„ì— í•´ë‹¹í•˜ëŠ” ì˜ìƒì´ ì—†ì–´ìš”. ì „ì²´ ì±„ë„ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                    ch_sub = ch_df.copy()
                    st.caption(f"(ì „ì²´ {len(ch_sub)}ê°œ ì˜ìƒ ë¶„ì„)")
                else:
                    st.caption(
                        f"{start_dt.date()} ~ {end_dt.date()}"
                    )
            else:
                st.info("ë‚ ì§œ ì •ë³´ê°€ ì—†ì–´ ì „ì²´ ì˜ìƒì„ ë¶„ì„í•©ë‹ˆë‹¤.")
                ch_sub = ch_df.copy()
                st.caption(f"(ì „ì²´ {len(ch_sub)}ê°œ ì˜ìƒ ë¶„ì„)")

        # ì´í›„ ì „ì²´ KPI/ì°¨íŠ¸/í…Œì´ë¸”ì€ ch_sub ê¸°ì¤€
        summary = build_channel_summary(ch_sub)

        # ... (KPI ì¹´ë“œ, TOP5, ì°¨íŠ¸ë“¤ ë“± ê¸°ì¡´ ì½”ë“œ ê³„ì†)


        st.subheader("ğŸ“Š ì±„ë„ ë¶„ì„")
        st.markdown("")

        # --- KPI ì¹´ë“œë“¤ ---
        kpi_cols = st.columns(3)

        # KPI ì¹´ë“œ 1: ì—…ë¡œë“œ í˜„í™©
        with kpi_cols[0]:
            with st.container(border=False):
                st.markdown("**ì—…ë¡œë“œ í˜„í™©**")
                st.markdown(f"### ì´ {summary['total_videos']}ê°œ")
                recent30 = summary.get("recent_30_cnt")
                if recent30 is not None:
                    st.caption(f"ìµœê·¼ 30ì¼ ì—…ë¡œë“œ: {recent30}ê°œ")
                else:
                    st.caption("ìµœê·¼ 30ì¼ ì—…ë¡œë“œ: -")

        # KPI ì¹´ë“œ 2: ì¡°íšŒìˆ˜ í¼í¬ë¨¼ìŠ¤
        def fmt_views(v):
            if v is None:
                return "-"
            return f"{int(v):,}íšŒ"

        with kpi_cols[1]:
            with st.container(border=False):
                st.markdown("**ì¡°íšŒìˆ˜ í‰ê· **")
                st.markdown(f"### {fmt_views(summary.get('avg_views_all'))}")
                st.caption(
                    # f"ì¤‘ì•™ê°’ {fmt_views(summary.get('median_views_all'))}"
                    f"ìµœê·¼ 5ê°œ í‰ê·  {fmt_views(summary.get('avg_views_recent5'))}"
                )

        # KPI ì¹´ë“œ 3: ì‹œì²­ì ë°˜ì‘ë„
        with kpi_cols[2]:
            with st.container(border=False):
                st.markdown("**ì‹œì²­ì ë°˜ì‘ë„**")
                avg_like_rate = summary.get("avg_like_rate")
                if avg_like_rate is not None and not np.isnan(avg_like_rate):
                    like_pct = avg_like_rate * 100.0
                    st.markdown(f"### {like_pct:.2f}%")
                else:
                    st.markdown("### í‰ê·  ì¢‹ì•„ìš”ìœ¨ -")
                st.caption("ì¢‹ì•„ìš”ìœ¨ = ì¢‹ì•„ìš”ìˆ˜ / ì¡°íšŒìˆ˜")

        # --- ìƒìœ„ í¼í¬ë¨¼ìŠ¤ ì˜ìƒ TOP 5 í…Œì´ë¸” ---
        st.markdown(" ")
        st.markdown("#### ğŸ”¥ ìƒìœ„ í¼í¬ë¨¼ìŠ¤ ì˜ìƒ TOP 5")
        top5_df = (
            ch_sub.sort_values("_views", ascending=False)
                 .loc[:, ["title", "_views", "_likes", "_comments", "_published_dt"]]
                 .head(5)
                 .rename(columns={
                     "title": "ì œëª©",
                     "_views": "ì¡°íšŒìˆ˜",
                     "_likes": "ì¢‹ì•„ìš”",
                     "_comments": "ëŒ“ê¸€",
                     "_published_dt": "ì—…ë¡œë“œì¼"
                 })
        )

        # ë³´ê¸° ì¢‹ì€ ë¬¸ìì—´ í¬ë§·
        top5_df["ì¡°íšŒìˆ˜"] = top5_df["ì¡°íšŒìˆ˜"].map(lambda x: f"{int(x):,}" if pd.notna(x) else "-")
        if "ì¢‹ì•„ìš”" in top5_df.columns:
            top5_df["ì¢‹ì•„ìš”"] = top5_df["ì¢‹ì•„ìš”"].map(lambda x: f"{int(x):,}" if pd.notna(x) else "-")
        if "ëŒ“ê¸€" in top5_df.columns:
            top5_df["ëŒ“ê¸€"] = top5_df["ëŒ“ê¸€"].map(lambda x: f"{int(x):,}" if pd.notna(x) else "-")

        st.dataframe(top5_df, use_container_width=True)

        # --- ì¡°íšŒìˆ˜ ì¶”ì´ ë¼ì¸ ì°¨íŠ¸ ---
        st.markdown(" ")
        st.markdown("#### ğŸ“ˆ ìµœê·¼ ì¡°íšŒìˆ˜ ì¶”ì´")

        time_df = ch_sub.dropna(subset=["_published_dt", "_views"]).copy()
        if len(time_df) > 0:
            time_df = time_df.sort_values("_published_dt")
            chart_views_over_time = (
                alt.Chart(time_df)
                .mark_line(point=True)
                .encode(
                    x=alt.X("_published_dt:T", title=""),
                    y=alt.Y("_views:Q", title=""),
                    tooltip=["title", "_published_dt", "_views"]
                )
                .properties(height=200)
            )
            st.altair_chart(chart_views_over_time, use_container_width=True)
        else:
            st.caption("ì—…ë¡œë“œì¼/ì¡°íšŒìˆ˜ ì •ë³´ê°€ ë¶€ì¡±í•´ ì¡°íšŒìˆ˜ ì¶”ì´ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # --- ë°˜ì‘ vs ì¡°íšŒìˆ˜ ì‚°ì ë„ ---
        st.markdown("#### ğŸ” ë°˜ì‘ vs ì¡°íšŒìˆ˜")
        corr_cols = st.columns(2)

        # ì¡°íšŒìˆ˜ vs ì¢‹ì•„ìš”ìˆ˜
        with corr_cols[0]:
            like_df = ch_sub.dropna(subset=["_views", "_likes"]).copy()
            if len(like_df) > 0:
                chart_like = (
                    alt.Chart(like_df)
                    .mark_circle(size=60)
                    .encode(
                        x=alt.X("_views:Q", title="ì¡°íšŒìˆ˜"),
                        y=alt.Y("_likes:Q", title="ì¢‹ì•„ìš”ìˆ˜"),
                        tooltip=["title", "_views", "_likes"]
                    )
                    .properties(height=220)
                )
                st.altair_chart(chart_like, use_container_width=True)
            else:
                st.caption("ì¢‹ì•„ìš” ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        # ì¡°íšŒìˆ˜ â†” ëŒ“ê¸€ìˆ˜
        with corr_cols[1]:
            cmt_df = ch_sub.dropna(subset=["_views", "_comments"]).copy()
            if len(cmt_df) > 0:
                chart_cmt = (
                    alt.Chart(cmt_df)
                    .mark_circle(size=60)
                    .encode(
                        x=alt.X("_views:Q", title="ì¡°íšŒìˆ˜"),
                        y=alt.Y("_comments:Q", title="ëŒ“ê¸€ìˆ˜"),
                        tooltip=["title", "_views", "_comments"]
                    )
                    .properties(height=220)
                )
                st.altair_chart(chart_cmt, use_container_width=True)
            else:
                st.caption("ëŒ“ê¸€ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        # --- ì—…ë¡œë“œ íƒ€ì´ë° ì„±ê³¼ ---
        st.markdown(" ")
        st.markdown("#### ğŸ•’ ì—…ë¡œë“œ íƒ€ì´ë° ì„±ê³¼")
        timing_cols = st.columns(2)

        # ìš”ì¼ë³„ í‰ê·  ì¡°íšŒìˆ˜
        with timing_cols[0]:
            st.markdown("**ìš”ì¼ë³„ í‰ê·  ì¡°íšŒìˆ˜**")
            dow_df = ch_sub.dropna(subset=["_dow", "_views"]).copy()
            if len(dow_df) > 0:
                dow_label = ["ì›”","í™”","ìˆ˜","ëª©","ê¸ˆ","í† ","ì¼"]

                def map_dow(d):
                    if pd.isna(d):
                        return "?"
                    try:
                        idx = int(d)
                    except Exception:
                        return "?"
                    if 0 <= idx <= 6:
                        return dow_label[idx]
                    return "?"

                dow_df["_dow_label"] = dow_df["_dow"].apply(map_dow)
                dow_mean = (
                    dow_df.groupby("_dow_label", as_index=False)["_views"].mean()
                          .rename(columns={"_views": "avg_views"})
                )
                chart_dow = (
                    alt.Chart(dow_mean)
                    .mark_bar()
                    .encode(
                        x=alt.X("_dow_label:N", title="ìš”ì¼"),
                        y=alt.Y("avg_views:Q", title="í‰ê·  ì¡°íšŒìˆ˜"),
                        tooltip=["_dow_label", "avg_views"]
                    )
                    .properties(height=200)
                )
                st.altair_chart(chart_dow, use_container_width=True)
            else:
                st.caption("ìš”ì¼ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")

        # ì‹œê°„ëŒ€ë³„ í‰ê·  ì¡°íšŒìˆ˜
        with timing_cols[1]:
            st.markdown("**ì—…ë¡œë“œ ì‹œê°„ëŒ€ë³„ í‰ê·  ì¡°íšŒìˆ˜**")
            st.caption("ì‹œê°„ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")

        st.divider()

    # ==========================
    # 2) ì¶”ì²œ ì œëª© ì¹´ë“œ ì„¹ì…˜
    # ==========================
    st.subheader("ğŸ“ ì¶”ì²œ ì œëª©")

    # ì¶”ì²œ ì œëª© ê·¼ê±° ë¬¸êµ¬ ìƒì„±
    def build_rationale(row, style):
        parts = []

        # í…œí”Œë¦¿/í‚¤ì›Œë“œ
        if isinstance(row.get("keyword_topk"), str):
            parts.append(
                f"í…œí”Œë¦¿ {row.get('template','?')}ì—ì„œ ìƒìœ„ í‚¤ì›Œë“œ `{row['keyword_topk']}`ë¥¼ ë°˜ì˜í–ˆìŠµë‹ˆë‹¤."
            )
        else:
            parts.append(
                f"í…œí”Œë¦¿ {row.get('template','?')}ì˜ ìƒìœ„ í‚¤ì›Œë“œë¥¼ ë°˜ì˜í–ˆìŠµë‹ˆë‹¤."
            )

        feats = []
        # ì œëª© ê¸¸ì´ vs ìƒìœ„10% í‰ê· 
        if "title_len" in row and "p10_len" in row:
            try:
                if abs(row["title_len"] - row["p10_len"]) <= 3:
                    feats.append("ì œëª© ê¸¸ì´ê°€ ìƒìœ„ 10% í‰ê· ê³¼ ìœ ì‚¬")
            except Exception:
                pass

        # ì´ëª¨ì§€ ì‚¬ìš©
        if "emoji_count" in row and p10_style:
            t = p10_style.get("emoji_target", None)
            if t is not None:
                try:
                    if abs(row["emoji_count"] - t) <= 1:
                        feats.append("ì´ëª¨ì§€ ì‚¬ìš©ì´ ìƒìœ„ 10% ë²”ìœ„")
                except Exception:
                    pass

        # ëŠë‚Œí‘œ ì‚¬ìš©
        if "exclaim_count" in row and p10_style:
            t = p10_style.get("exclaim_target", None)
            if t is not None:
                try:
                    if abs(row["exclaim_count"] - t) <= 1:
                        feats.append("ëŠë‚Œí‘œ ì‚¬ìš©ì´ ìƒìœ„ 10% ë²”ìœ„")
                except Exception:
                    pass

        # ì‹ ì„ ë„ / ì¸ë„¤ì¼ ì ìˆ˜
        if "novelty_score" in row and row["novelty_score"] >= 0.4:
            feats.append("ì œëª© ì‹ ì„ ë„(í‘œí˜„ ë‹¤ì–‘ì„±)ê°€ ë†’ìŒ")
        if "thumbnail_score" in row and row["thumbnail_score"] >= 0.65:
            feats.append("ì¸ë„¤ì¼ ê°€ë…ì„±/ëŒ€ë¹„ ì ìˆ˜ê°€ ë†’ìŒ")

        if feats:
            parts.append(" / ".join(feats))

        return " ".join(parts)

    def safe_rationale(row, style):
        try:
            return str(build_rationale(row, style))
        except Exception:
            return ""

    # ì¶”ì²œ ì œëª©ë“¤ ì •ë ¬ (ì˜ˆì¸¡ ì¡°íšŒìˆ˜ ë†’ì€ ìˆœ)
    df_view = df.sort_values(["predicted_views"], ascending=False).reset_index(drop=True)
    df_view["rationale"] = df_view.apply(lambda r: safe_rationale(r, p10_style), axis=1)

    # ì¹´ë“œ ë Œë”
    for _, row in df_view.iterrows():
        with st.container(border=True):
            st.markdown(f"##### {row['recommended_title']}")
            cols_block = st.columns(1)
            cols_block[0].write(f"**í…œí”Œë¦¿:** {row.get('template','-')}")
            st.caption(row["rationale"])

    # ==========================
    # 3) GLOBAL INSIGHTS
    # ==========================
    st.divider()
    st.subheader("ğŸ“ˆ í…œí”Œë¦¿/í‚¤ì›Œë“œ íŠ¸ë Œë“œ íŒ¨í„´")

    # í…œí”Œë¦¿ í™œìš© ë¹„ì¤‘
    if tpl_stats is not None:
        st.markdown("**í…œí”Œë¦¿ í™œìš© ë¹„ì¤‘ TOP**")
        top_tpl = tpl_stats.sort_values("share", ascending=False).head(8)
        chart_tpl = (
            alt.Chart(top_tpl)
            .mark_bar()
            .encode(
                x=alt.X("share:Q", axis=alt.Axis(format="%"), title="í™œìš© ë¹„ì¤‘"),
                y=alt.Y("template:N", sort="-x", title="í…œí”Œë¦¿"),
                tooltip=["template", "share", "avg_pred_views", "count"]
            )
        )
        st.altair_chart(chart_tpl, use_container_width=True)

    # í‚¤ì›Œë“œ ì˜í–¥ë ¥
    if kw_stats is not None:
        st.markdown("**í‚¤ì›Œë“œ ì˜í–¥ë ¥**")
        kw_mode = st.radio("ì •ë ¬ ê¸°ì¤€", ["score_sum"], horizontal=True, key="kw_sort")
        top_kw = kw_stats.sort_values(kw_mode, ascending=False).head(15)
        chart_kw = (
            alt.Chart(top_kw)
            .mark_bar()
            .encode(
                x=alt.X(f"{kw_mode}:Q", title=kw_mode),
                y=alt.Y("keyword:N", sort="-x", title="í‚¤ì›Œë“œ"),
                tooltip=["keyword", "score_avg", "score_sum", "freq"]
            )
        )
        st.altair_chart(chart_kw, use_container_width=True)
