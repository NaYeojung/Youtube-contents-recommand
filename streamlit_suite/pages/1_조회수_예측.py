# -*- coding: utf-8 -*-
import os, sys, tempfile, json, io, ast
import numpy as np
import pandas as pd
import streamlit as st
from collections import Counter
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

# Matplotlib í•œê¸€ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

# =========================================
# ê²½ë¡œ/ëª¨ë“ˆ ë¡œë“œ
# =========================================
WEB_DIR = r"C:\web"  # í•„ìš” ì‹œ ìˆ˜ì •
if WEB_DIR not in sys.path:
    sys.path.append(WEB_DIR)

try:
    from feature import process_user_input
except Exception as e:
    st.set_page_config(page_title="TubeBoost", layout="wide", page_icon="ğŸ¬")
    st.error(f"feature.py import ì‹¤íŒ¨: {e}")
    st.stop()

st.set_page_config(page_title="ì¡°íšŒìˆ˜ ì˜ˆì¸¡", layout="wide", page_icon="ğŸ¬")

# =========================================
# ìœ í‹¸ í•¨ìˆ˜ / í—¬í¼
# =========================================
FEATURE_LABELS = {
    "title_length": "ì œëª© ê¸¸ì´",
    "word_count": "ì œëª© ë‹¨ì–´ ìˆ˜",
    "emoji_count": "ì œëª© ì´ëª¨ì§€ ìˆ˜",
    "special_char_count": "íŠ¹ìˆ˜ë¬¸ì ìˆ˜",
    "person_count": "ì¸ë„¤ì¼ ì‚¬ëŒ ìˆ˜",
    "object_count": "ì¸ë„¤ì¼ ê°ì²´ ìˆ˜",
    "has_text": "ì¸ë„¤ì¼ í…ìŠ¤íŠ¸ í¬í•¨ ì—¬ë¶€",
    "brightness": "ì¸ë„¤ì¼ ë°ê¸°",
    "contrast": "ì¸ë„¤ì¼ ëŒ€ë¹„",
    "has_question_mark": "ì œëª© ? í¬í•¨ ì—¬ë¶€",
    "has_exclamation": "ì œëª© ! í¬í•¨ ì—¬ë¶€",
    "duration": "ì˜ìƒ ê¸¸ì´",
}
def get_label(k: str) -> str:
    return FEATURE_LABELS.get(k, k)

def _safe_mean(series_like):
    try:
        return float(pd.to_numeric(series_like, errors="coerce").mean())
    except Exception:
        return np.nan

def _predict_views_by_regressor(model, df, cols):
    pred = model.predict(df[cols].values)
    # ë¡œê·¸ ìŠ¤ì¼€ì¼ íšŒê·€ ëª¨ë¸ ê°€ì • â†’ expm1 ì‹œë„
    try:
        return int(np.expm1(pred[0]))
    except Exception:
        try:
            return int(float(pred[0]))
        except Exception:
            return None

def load_csv_compat(path: str) -> pd.DataFrame:
    """ì¸ì½”ë”©/engine ì°¨ì´ë¡œ ì¸í•œ ë¡œë“œ ì‹¤íŒ¨ë¥¼ ì¤„ì´ê¸° ìœ„í•œ ì•ˆì „í•œ CSV ë¡œë”"""
    encodings = ["utf-8", "utf-8-sig", "cp949", "euc-kr", "latin1"]
    engines = ["c", "python"]
    last_err = None
    for enc in encodings:
        for eng in engines:
            try:
                with open(path, "r", encoding=enc, errors="ignore") as f:
                    return pd.read_csv(f, engine=eng)
            except Exception as e:
                last_err = e
                continue
    raise last_err if last_err else FileNotFoundError(path)

def parse_object_labels(obj_details):
    """object_details(dict/list/str)ì—ì„œ ë¼ë²¨ë³„ ë“±ì¥ ë¹ˆë„ë¥¼ ì‹œë¦¬ì¦ˆë¡œ ë°˜í™˜"""
    try:
        v = obj_details
        if isinstance(v, str):
            v = json.loads(v)
    except Exception:
        try:
            v = ast.literal_eval(obj_details)
        except Exception:
            v = {}
    if isinstance(v, dict):
        objs = v.get("objects", [])
    elif isinstance(v, list):
        objs = v
    else:
        objs = []
    labels = [o.get("label", "unknown") for o in objs if isinstance(o, dict)]
    if not labels:
        return pd.Series(dtype=int)
    return pd.Series(labels).value_counts().sort_values(ascending=False)

def extract_text_samples(text_details, topk=5):
    """text_details(list/str)ì—ì„œ ë†’ì€ í™•ë¥  í…ìŠ¤íŠ¸ ìƒ˜í”Œë§Œ ë½‘ì•„ì„œ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¡œ"""
    try:
        v = text_details
        if isinstance(v, str):
            v = json.loads(v)
    except Exception:
        try:
            v = ast.literal_eval(text_details)
        except Exception:
            v = []
    rows = []
    for t in v if isinstance(v, list) else []:
        txt = t.get("text", "")
        prob = float(t.get("probability", 0.0))
        rows.append((prob, txt))
    rows.sort(key=lambda x: x[0], reverse=True)
    return [f"{txt} (p={prob:.2f})" for prob, txt in rows[:topk] if txt]

def chip(text: str):
    # ì œëª©ì—ì„œ ì¶”ì¶œí•œ ì£¼ìš” ëª…ì‚¬ chip
    return (
        "<span style='display:inline-block;"
        "padding:4px 10px;margin:4px;border-radius:999px;"
        "background:#F1F5F9;border:1px solid #E2E8F0;"
        "font-size:12px'>"
        f"{text}</span>"
    )

def color_chip(name: str):
    # ì¶”ì¶œëœ ëŒ€í‘œ ìƒ‰ìƒ ì‹œê°ìš© ì¹©
    bg = name
    return (
        "<span style='display:inline-block;"
        "padding:6px 12px;margin:4px;border-radius:10px;"
        "border:1px solid #e5e7eb;"
        f"background:{bg};color:#111827;font-weight:600'>{name}</span>"
    )

def get_peer_subset(md: pd.DataFrame, my_subs: int, pct: float, min_rows: int = 100) -> pd.DataFrame:
    """
    mdì—ì„œ ë‚´ êµ¬ë…ììˆ˜ Â±pct% ë²”ìœ„ì˜ ì˜ìƒë“¤ë§Œ ì¶”ë¦¼.
    min_rows ë¯¸ë§Œì´ë©´ ë²”ìœ„ë¥¼ ì ì°¨ ëŠ˜ë ¤ì„œ(ìµœëŒ€ Â±50%) ì¶©ë¶„í•œ í‘œë³¸ í™•ë³´.
    """
    if "subscriber_count" not in md.columns:
        return pd.DataFrame()
    subs = pd.to_numeric(md["subscriber_count"], errors="coerce")
    md2 = md.copy()
    md2["subscriber_count"] = subs

    p = max(0.01, pct / 100.0)
    my = float(my_subs)
    lo, hi = my * (1 - p), my * (1 + p)

    peer = pd.DataFrame()
    for _ in range(10):  # ìµœëŒ€ 10ë²ˆ (ëŒ€ëµ Â±50%ê¹Œì§€)
        peer = md2[(md2["subscriber_count"] >= lo) & (md2["subscriber_count"] <= hi)]
        if len(peer) >= min_rows or p >= 0.5:
            break
        p *= 1.25
        lo, hi = my * (1 - p), my * (1 + p)
    return peer

def plot_sensitivity_barh(delta_df: pd.DataFrame, topn: int = 5, title: str = ""):
    """
    delta_df: columns => ['ì§€í‘œ','ì¦ê°(ì˜ˆì¸¡)']
    topnê°œ ì§€í‘œë§Œ ê°€ë¡œ ë§‰ëŒ€ë¡œ ì‹œê°í™”.
    """
    if delta_df is None or delta_df.empty or "ì¦ê°(ì˜ˆì¸¡)" not in delta_df.columns:
        return

    plot_df = (
        delta_df.dropna(subset=["ì¦ê°(ì˜ˆì¸¡)"])
                .sort_values("ì¦ê°(ì˜ˆì¸¡)", ascending=False)
                .head(topn)
    )
    if plot_df.empty:
        return

    fig, ax = plt.subplots(figsize=(6, 3))
    colors = ["#80D2FF" if v > 0 else "#E57373" for v in plot_df["ì¦ê°(ì˜ˆì¸¡)"]]

    ax.barh(plot_df["ì§€í‘œ"], plot_df["ì¦ê°(ì˜ˆì¸¡)"], color=colors)
    ax.invert_yaxis()
    ax.axvline(0, color="gray", lw=1)
    ax.set_title(title)

    for i, v in enumerate(plot_df["ì¦ê°(ì˜ˆì¸¡)"]):
        ax.text(
            v + (0.02 * max(plot_df["ì¦ê°(ì˜ˆì¸¡)"].max(), 1)),
            i,
            f"{int(v):+}",
            va="center",
            ha="left" if v >= 0 else "right",
            fontsize=8,
        )

    st.pyplot(fig)

def render_change_row(label, cur_val, tgt_val, gain=None):
    """
    ì§€í‘œë³„ë¡œ 'ì§€ê¸ˆ vs ì¶”ì²œ' ë¹„êµ ì¹´ë“œ í•œ ì¤„ ë Œë”
    """
    diff=float(cur_val)-float(tgt_val)
    arrow = "â¡ï¸"
    gain_txt = ""
    if gain is not None:
        if gain > 0:
            gain_txt = f"<span style='color:#16a34a;font-weight:600;'>+{gain:,}â†‘</span>"
        elif gain < 0:
            gain_txt = f"<span style='color:#dc2626;font-weight:600;'>{gain:,}â†“</span>"

    if abs(diff) < 1e-6:
        base_phrase = "ê°€ í‰ê· ê³¼ ìœ ì‚¬í•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤."
    else:
        if diff > 0:
            if "ê¸¸ì´" in label:
                base_phrase = "ê°€ ê¸´ í¸ì…ë‹ˆë‹¤."
            elif "ìˆ˜" in label:
                base_phrase = "ê°€ ë§ì€ í¸ì…ë‹ˆë‹¤."
            elif "ë°ê¸°" in label or "ëŒ€ë¹„" in label:
                base_phrase = "ê°€ ë†’ì€ í¸ì…ë‹ˆë‹¤."
            else:
                base_phrase = "ê°€ ë†’ì€ í¸ì…ë‹ˆë‹¤."
        else:
            if "ê¸¸ì´" in label:
                base_phrase = "ê°€ ì§§ì€ í¸ì…ë‹ˆë‹¤."
            elif "ìˆ˜" in label:
                base_phrase = "ê°€ ì ì€ í¸ì…ë‹ˆë‹¤."
            elif "ë°ê¸°" in label or "ëŒ€ë¹„" in label:
                base_phrase = "ê°€ ë‚®ì€ í¸ì…ë‹ˆë‹¤."
            else:
                base_phrase = "ê°€ ë‚®ì€ í¸ì…ë‹ˆë‹¤."

    st.markdown(
        f"""
        <div style="
            border:1px solid #e5e7eb;
            border-radius:10px;
            padding:8px 12px;
            margin-bottom:6px;
            background:#f9fafb;
            font-size:18px;
            line-height:2;
        ">
            <div style="font-weight:600; color:#111827;">{label}
            <span style="font-weigth:300;">{base_phrase}</span>
            </div>
            <div style="color:#374151;">
                <span style="color:#4b5563;"> í˜„ì¬ </span>
                <strong style="color:#111827;"> {cur_val:.1f} </strong>
                {arrow}
                <span style="color:#4b5563;"> ì¶”ì²œ </span>
                <strong style="color:#111827;"> {tgt_val:.1f} </strong>
                {("&nbsp; &nbsp; &nbsp;" + gain_txt) if gain_txt else ""}
            </div>
        </div>
        """,
        unsafe_allow_html=True
    )

# =========================================
# ì‚¬ì´ë“œë°” (í”¼ì–´ ë¹„êµ ì„¤ì •)
# =========================================
with st.sidebar:
    st.subheader("ë¹„êµ ê¸°ì¤€ ì„¤ì •")
    peer_pct = st.slider(
        "êµ¬ë…ì ë²”ìœ„(Â±%)",
        min_value=1,
        max_value=50,
        value=15,
        step=1,
        help="ë‚´ êµ¬ë…ì ìˆ˜ì˜ Â±ë²”ìœ„ë¡œ ìœ ì‚¬ êµ¬ë…ì ì±„ë„ì„ ì„ íƒí•©ë‹ˆë‹¤.",
    )
    peer_min_rows = st.number_input(
        "ìµœì†Œ í‘œë³¸ ìˆ˜",
        min_value=20,
        value=100,
        step=10,
        help="ë²”ìœ„ ë‚´ í‘œë³¸ì´ ë¶€ì¡±í•˜ë©´ ìë™ìœ¼ë¡œ ë²”ìœ„ë¥¼ ë„“í™ë‹ˆë‹¤.",
    )

    st.divider()
    st.subheader("ëª¨ë¸/ë°ì´í„° ê²½ë¡œ")
    saved_models_dir = st.text_input(
        "saved_models ê²½ë¡œ",
        value=os.path.join(WEB_DIR, "saved_models"),
    )
    model_datas_path = st.text_input(
        "model_datas.csv ê²½ë¡œ",
        value=os.path.join(WEB_DIR, "model_datas.csv"),
    )

# =========================================
# í—¤ë” / íˆì–´ë¡œ ì„¹ì…˜
# =========================================
hero_left, hero_cen, hero_right = st.columns([0.6, 0.1, 0.3])
with hero_left:
    st.markdown("### ğŸ¬ ì˜ìƒ ì¡°íšŒìˆ˜ ì˜ˆì¸¡")
    st.markdown(
        "ì œëª©ê³¼ ì¸ë„¤ì¼ì„ ê¸°ë°˜ìœ¼ë¡œ ì´ ì˜ìƒì´ ì–´ëŠ ì •ë„ì˜ ì¡°íšŒìˆ˜ë¥¼ ë‚¼ ìˆ˜ ìˆì„ì§€ "
        "**ì‚¬ì „ì— ì§„ë‹¨**í•©ë‹ˆë‹¤."
    )
    st.caption(
        "ì œëª© í†¤ Â· í‚¤ì›Œë“œ í›… Â· ì´ëª¨ì§€/íŠ¹ìˆ˜ë¬¸ì ì‚¬ìš© Â· ì¸ë„¤ì¼ êµ¬ë„ì™€ ê°€ì‹œì„± ë“±ì„ ë°”íƒ•ìœ¼ë¡œ "
        "í´ë¦­ ì ì¬ë ¥ì„ ì¶”ì •í•˜ê³  ê°œì„  í¬ì¸íŠ¸ë¥¼ ì œì•ˆí•´ìš”."
    )

with hero_right:
    with st.container(border=True):
        st.caption("ì´ í˜ì´ì§€ì—ì„œ í•  ìˆ˜ ìˆëŠ” ê²ƒ")
        st.markdown(
            "- ì§€ê¸ˆ ì‘ì„±í•œ ì œëª©ì´ ì˜ í´ë¦­ë˜ëŠ” êµ¬ì¡°ì¸ì§€ í™•ì¸\n"
            "- ì¸ë„¤ì¼/ì¹´í”¼ ì¡°í•©ì˜ ê°•ì Â·ì•½ì  ì²´í¬\n"
            "- ì¡°íšŒìˆ˜ ì ì¬ë ¥(ì˜ˆì¸¡ê°’) í™•ì¸"
        )

st.markdown("---")

# =========================================
# 1. ì‚¬ìš©ì ì…ë ¥ í¼
# =========================================
st.subheader("1. ë¶„ì„í•  ì˜ìƒ ì •ë³´ ì…ë ¥")

with st.container(border=True):
    st.caption("ì œëª© / ì¸ë„¤ì¼ / ë©”íƒ€ ì •ë³´ë¥¼ ì…ë ¥í•˜ì„¸ìš”. ì‹¤í–‰í•˜ë©´ ë¶„ì„ì´ ì‹œì‘ë©ë‹ˆë‹¤.")

    with st.form("predict_form"):
        c1, c2 = st.columns([3, 2])
        with c1:
            title = st.text_input(
                "ì œëª©",
                value="ì¸ìƒì—¬í–‰ì§€ì˜€ë˜ ë‰´ìš•ì— ë‹¤ì‹œ í˜¼ì ì…ì¥! ê·¼ë° ì™œ ì´ë ‡ê²Œ ë³€í•¨...? (ì° ë‰´ìš”ì»¤ê°€ ì¶”ì²œí•´ì¤€ ë¹µì§‘, ë§›ì§‘, ì¹´í˜ ë‹¤ ë¿Œì‹œê¸´í•¨ã…£ìŠ¤í‚´ìŠ¤ ì—‰ë½• ëŒ€ë‚œë¦¬)",
            )
            thumbnail_url = st.text_input(
                "ì¸ë„¤ì¼ URL",
                value="https://i.ytimg.com/vi/D-jOG2ybV1s/hq720.jpg",
            )
            thumbnail_file = st.file_uploader(
                "ë˜ëŠ” ì´ë¯¸ì§€ ì—…ë¡œë“œ",
                type=["png", "jpg", "jpeg", "webp"],
            )
        with c2:
            duration = st.text_input("ì˜ìƒ ê¸¸ì´ (MM:SS)", value="36:40")
            subscriber = st.number_input(
                "êµ¬ë…ì ìˆ˜",
                min_value=0,
                value=230000,
                step=1000,
            )
            total_videos = st.number_input(
                "ëˆ„ì  ì—…ë¡œë“œ ìˆ˜",
                min_value=0,
                value=600,
                step=1,
            )
            category = st.text_input("ì¹´í…Œê³ ë¦¬", value="General")
        run = st.form_submit_button("ì¡°íšŒìˆ˜ ì˜ˆì¸¡ ì‹¤í–‰ ğŸ”")

# =========================================
# 2. ì‹¤ì œ ë¶„ì„ ì‹¤í–‰ ë° ê²°ê³¼ ì¶œë ¥
# =========================================
if run:
    # -------------------------------------
    # ì¸ë„¤ì¼ ì…ë ¥ ì •ë¦¬ (URL ë˜ëŠ” ì—…ë¡œë“œ íŒŒì¼)
    # -------------------------------------
    tmp_path = None
    if thumbnail_url.strip():
        thumb_input = thumbnail_url.strip()
    elif thumbnail_file is not None:
        suffix = os.path.splitext(thumbnail_file.name)[1].lower() or ".jpg"
        fd, tmp_path = tempfile.mkstemp(suffix=suffix)
        os.close(fd)
        with open(tmp_path, "wb") as f:
            f.write(thumbnail_file.read())
        thumb_input = tmp_path
    else:
        st.error("ì¸ë„¤ì¼ URLì„ ì…ë ¥í•˜ê±°ë‚˜ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        st.stop()

    try:
        # -------------------------------------
        # 2-1. feature.pyë¡œ í”¼ì²˜ ì¶”ì¶œ & í´ëŸ¬ìŠ¤í„° ì˜ˆì¸¡
        # -------------------------------------
        df, cluster = process_user_input(
            title,
            thumb_input,
            duration,
            subscriber,
            total_videos,
            category,
        )
        row = df.iloc[0].to_dict()

        # -------------------------------------
        # 2-2. í´ëŸ¬ìŠ¤í„°ë³„ íšŒê·€ ëª¨ë¸ ë¶ˆëŸ¬ì™€ ì¡°íšŒìˆ˜ ì˜ˆì¸¡
        # -------------------------------------
        predicted_views = None
        feat_cols = [
            'duration','subscriber_count','brightness','contrast',
            'title_length','word_count','emoji_count','special_char_count',
            'is_clickbait','has_question_mark','has_exclamation',
            'pub_year','pub_month','pub_weekday',
            'color_red','color_blue','color_green','color_yellow',
            'color_purple','color_brown','color_grey','color_white','color_pink',
            'person_count','object_count','has_text',
            'person_left','person_middle','person_right',
            'person_small','person_medium','person_large',
            'text_left','text_middle','text_right',
            'text_small','text_medium','text_large'
        ]
        for c in feat_cols:
            if c not in df.columns:
                df[c] = 0

        import joblib
        reg, cluster_mean, cluster_top10_mean = None, None, None
        model_path = os.path.join(saved_models_dir, f"model_cluster_{cluster}.pkl")
        if os.path.exists(model_path):
            try:
                reg = joblib.load(model_path)
                predicted_views = _predict_views_by_regressor(reg, df, feat_cols)
            except Exception as e:
                st.warning(f"íšŒê·€ ëª¨ë¸ ë¡œë”©/ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")

        # -------------------------------------
        # 2-3. í´ëŸ¬ìŠ¤í„° í†µê³„ (í‰ê·  / ìƒìœ„10%)
        # -------------------------------------
        md = None
        if os.path.exists(model_datas_path):
            try:
                md = load_csv_compat(model_datas_path)
                md["cluster"] = pd.to_numeric(md.get("cluster"), errors="coerce")
                filt = md[md["cluster"] == cluster]
                if len(filt):
                    cluster_mean = int(_safe_mean(filt.get("view_count")))
                    top10 = filt.nlargest(max(1, int(len(filt)*0.1)), "view_count")
                    cluster_top10_mean = int(_safe_mean(top10.get("view_count")))
            except Exception as e:
                st.warning(f"model_datas.csv ì½ê¸° ì‹¤íŒ¨: {e}")

        # -------------------------------------
        # 2-4. ìœ ì‚¬ êµ¬ë…ìêµ°(peer) í†µê³„
        # -------------------------------------
        peer_mean_views = None
        peer_top10_mean_views = None
        peer_avg_core = None
        peer_avg_dict = {}

        if md is not None and len(md):
            peer_df = get_peer_subset(md, int(row.get("subscriber_count", 0)), peer_pct, peer_min_rows)
            if len(peer_df):
                # ì¡°íšŒìˆ˜ í‰ê· 
                if "view_count" in peer_df.columns:
                    peer_mean_views = int(_safe_mean(peer_df["view_count"]))
                    top10_peer = peer_df.nlargest(
                        max(1, int(len(peer_df) * 0.1)),
                        "view_count"
                    )
                    peer_top10_mean_views = int(_safe_mean(top10_peer["view_count"]))

                # í•µì‹¬ ì§€í‘œ í‰ê·  (ê¸¸ì´/ë°ê¸° ë“±)
                core_cols = [
                    "duration","title_length","word_count","emoji_count","special_char_count",
                    "has_question_mark","has_exclamation","brightness","contrast",
                    "person_count","object_count","has_text"
                ]
                peer_avg_core = {}
                for c in core_cols:
                    if c in peer_df.columns:
                        peer_avg_core[c] = round(_safe_mean(peer_df[c]), 3)

                # ë ˆì´ì•„ì›ƒ ë¶„í¬ í‰ê· (ì‚¬ëŒ, í…ìŠ¤íŠ¸ ìœ„ì¹˜ ë“±)
                dist_cols = [
                    "text_left","text_middle","text_right",
                    "text_small","text_medium","text_large",
                    "person_left","person_middle","person_right",
                    "person_small","person_medium","person_large",
                ]
                for c in dist_cols:
                    if c in peer_df.columns:
                        peer_avg_dict[c] = float(_safe_mean(peer_df[c]))
                    else:
                        peer_avg_dict[c] = 0.0

        # -------------------------------------
        # 2-5. í–¥ìƒ ì‹œë®¬ë ˆì´ì…˜ (í”¼ì–´ í‰ê· ìœ¼ë¡œ ë§ì·„ì„ ë•Œ)
        # -------------------------------------
        current_pred_views, improved_pred_views = None, None
        lift_abs, lift_pct = None, None
        top_change_rows, drivers_text = pd.DataFrame(), ""

        if reg is not None and peer_avg_core:
            # ë‚´ë¶€ì ìœ¼ë¡œ ì˜ˆì¸¡í•´ë³´ëŠ” í—¬í¼
            def simulate(modified):
                new_df = df.copy()
                for k, v in modified.items():
                    new_df.at[0, k] = v
                return _predict_views_by_regressor(reg, new_df, feat_cols)

            sims = []
            target_keys = [
                'title_length','emoji_count','special_char_count','person_count','has_text',
                'brightness','contrast','word_count','object_count'
            ]
            for k in target_keys:
                if k not in peer_avg_core:
                    continue
                cur_val = float(df.iloc[0].get(k, 0))
                peer_val = float(peer_avg_core[k])
                # ì •ìˆ˜í˜•ìœ¼ë¡œ ë³´ëŠ” ì§€í‘œëŠ” ë°˜ì˜¬ë¦¼
                if k in ['emoji_count','special_char_count','person_count','has_text',
                         'word_count','object_count','title_length']:
                    peer_val = int(round(peer_val))

                pred_peer = simulate({k: peer_val})
                diff_val = None
                if predicted_views and pred_peer:
                    diff_val = int(pred_peer) - int(predicted_views)

                sims.append({
                    "ì§€í‘œ":k,
                    "í˜„ì¬ê°’":cur_val,
                    "í‰ê· ê°’":peer_val,
                    "í‰ê· ìœ¼ë¡œ ë§ì¶œ ë•Œ ì˜ˆì¸¡":pred_peer,
                    "ì¦ê°(ì˜ˆì¸¡)":diff_val
                })

            delta_views_df = pd.DataFrame(sims)

            # ì—¬ëŸ¬ ê°œì„ ì„ ë™ì‹œì— ì ìš©
            improving_changes = {
                r["ì§€í‘œ"]: r["í‰ê· ê°’"]
                for _, r in delta_views_df.iterrows()
                if r["ì¦ê°(ì˜ˆì¸¡)"] and r["ì¦ê°(ì˜ˆì¸¡)"] > 0
            }
            pred_combo = simulate(improving_changes) if improving_changes else None

            current_pred_views = int(predicted_views) if predicted_views else None
            improved_pred_views = int(pred_combo) if pred_combo else None

            if current_pred_views and improved_pred_views:
                lift_abs = improved_pred_views - current_pred_views
                lift_pct = (
                    (lift_abs / current_pred_views) * 100
                    if current_pred_views > 0 else None
                )

            top_change_rows = (
                delta_views_df
                .dropna(subset=["ì¦ê°(ì˜ˆì¸¡)"])
                .sort_values("ì¦ê°(ì˜ˆì¸¡)", ascending=False)
                .head(3)
            )
            drivers_text = ", ".join(
                get_label(v) for v in top_change_rows["ì§€í‘œ"].tolist()
            ) if not top_change_rows.empty else ""

        # -------------------------------------
        # 2-6. ìƒë‹¨ ìš”ì•½ ì„¹ì…˜
        # -------------------------------------
        st.success(f"ë¶„ì„ì´ ì™„ë£ŒëìŠµë‹ˆë‹¤. í´ëŸ¬ìŠ¤í„° {cluster}ê°€ ì ìš©ë©ë‹ˆë‹¤.")
        st.markdown(" ")

        topA, topB = st.columns([3, 2])
        with topA:
            with st.container(border=True):
                st.markdown("#### ğŸ“Œ ì¸ì‚¬ì´íŠ¸ ìš”ì•½")
                lines = []

                if current_pred_views:
                    lines.append(
                        f"- í˜„ì¬ êµ¬ì„±ìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ì¡°íšŒìˆ˜: ì•½ {current_pred_views:,}íšŒ"
                    )
                if improved_pred_views and lift_abs and lift_pct:
                    lines.append(
                        f"- í•µì‹¬ ì§€í‘œë¥¼ í‰ê·  ìˆ˜ì¤€ìœ¼ë¡œ ì¡°ì • ì‹œ: ì•½ {improved_pred_views:,}íšŒ ì˜ˆìƒ"
                    )
                    lines.append(
                        f"  (ì¶”ì • +{lift_abs:,} / {lift_pct:.1f}% í–¥ìƒ)"
                    )
                if drivers_text:
                    lines.append(
                        f"- íŠ¹íˆ **{drivers_text}** ì§€í‘œê°€ ì¡°íšŒìˆ˜ì— í° ì˜í–¥ì„ ì£¼ëŠ” ì‹ í˜¸"
                    )

                # if cluster_mean:
                #     lines.append(
                #         f"- ì´ í´ëŸ¬ìŠ¤í„° í‰ê·  ì¡°íšŒìˆ˜: ì•½ {cluster_mean:,}íšŒ"
                #     )
                # if cluster_top10_mean:
                #     lines.append(
                #         f"- ìƒìœ„ 10% í‰ê·  ì¡°íšŒìˆ˜: ì•½ {cluster_top10_mean:,}íšŒ"
                #     )

                # if peer_mean_views:
                #     lines.append(
                #         f"- ìœ ì‚¬ êµ¬ë…ì ì±„ë„ í‰ê·  ì¡°íšŒìˆ˜: ì•½ {peer_mean_views:,}íšŒ"
                #     )
                # if peer_top10_mean_views:
                #     lines.append(
                #         f"- ìœ ì‚¬ êµ¬ë…ì ìƒìœ„ 10% í‰ê· : ì•½ {peer_top10_mean_views:,}íšŒ"
                #     )

                if lines:
                    st.write("\n".join(lines))
                else:
                    st.write("ìš”ì•½ ì •ë³´ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        with topB:
            with st.container(border=True):
                st.markdown("#### ì¸ë„¤ì¼ ë¯¸ë¦¬ë³´ê¸°")
                try:
                    st.image(thumb_input, caption="", use_container_width=True)
                except Exception:
                    st.caption("ì¸ë„¤ì¼ ì´ë¯¸ì§€ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("---")

        # -------------------------------------
        # 3. ì œëª© ë¶„ì„
        # -------------------------------------
        st.subheader("2. ì œëª© ë¶„ì„")

        with st.container(border=True):
            tcol1, tcol2, tcol3 = st.columns(3)
            tcol1.metric("ì œëª© ê¸¸ì´", int(row.get("title_length", 0)))
            tcol2.metric("ë‹¨ì–´ ìˆ˜", int(row.get("word_count", 0)))
            tcol3.metric("íŠ¹ìˆ˜ë¬¸ì ìˆ˜", int(row.get("special_char_count", 0)))

            tcol1.metric("ì´ëª¨ì§€ ìˆ˜", int(row.get("emoji_count", 0)))
            tcol2.metric("? í¬í•¨", "Yes" if int(row.get("has_question_mark", 0)) else "No")
            tcol3.metric("! í¬í•¨", "Yes" if int(row.get("has_exclamation", 0)) else "No")

            nouns = [
                row.get("top_noun_1",""),
                row.get("top_noun_2",""),
                row.get("top_noun_3",""),
            ]
            nouns = [n for n in nouns if str(n).strip()]
            if nouns:
                st.markdown("**ìƒìœ„ ëª…ì‚¬(Top Nouns)**")
                st.markdown("".join(chip(n) for n in nouns), unsafe_allow_html=True)

        st.markdown("---")

        # -------------------------------------
        # 4. ì¸ë„¤ì¼ ë¶„ì„
        # -------------------------------------
        st.subheader("3. ì¸ë„¤ì¼ ë¶„ì„")

        with st.container(border=True):
            scol1, scol2, scol3 = st.columns(3)
            scol1.metric("ë°ê¸°", f"{float(row.get('brightness',0)):.1f}")
            scol2.metric("ëŒ€ë¹„",  f"{float(row.get('contrast',0)):.1f}")
            scol3.metric("í…ìŠ¤íŠ¸ ì¡´ì¬", "Yes" if int(row.get("has_text", 0)) else "No")

            scol1.metric("ì‚¬ëŒ ìˆ˜", int(row.get("person_count", 0)))
            scol2.metric("ê°ì²´ ìˆ˜", int(row.get("object_count", 0)))
            try:
                h, w = row.get("thumbnail_size", (None,None))
                scol3.metric("ì´ë¯¸ì§€ í¬ê¸°", f"{w}Ã—{h}" if h and w else "â€”")
            except Exception:
                pass

            st.markdown("**ì£¼ìš” ìƒ‰ìƒ**")
            dom_colors = []
            if isinstance(row.get("dominant_colors"), str):
                dom_colors = [
                    c.strip()
                    for c in row["dominant_colors"].split(",")
                    if c.strip()
                ]
            if dom_colors:
                st.markdown(
                    "".join(color_chip(c) for c in dom_colors),
                    unsafe_allow_html=True
                )

            # --- ì„¸ë¶€ ì¸ë„¤ì¼ ë¶„ì„ (ê°ì²´/í…ìŠ¤íŠ¸ ë ˆì´ì•„ì›ƒ) ---
            st.markdown(" ")
            with st.expander("ğŸ” ì¸ë„¤ì¼ ì„¸ë¶€ ë¶„ì„"):
                # ê°ì²´ ë¼ë²¨ ë¹ˆë„
                lbl_counts = parse_object_labels(row.get("object_details", {}))

                # OCR í…ìŠ¤íŠ¸ ë””í…Œì¼ ê°€ê³µ
                text_details_raw = row.get("text_details", [])
                if isinstance(text_details_raw, str):
                    try:
                        text_details_raw = ast.literal_eval(text_details_raw)
                    except Exception:
                        text_details_raw = []

                text_tokens = []
                for item in text_details_raw:
                    txt = str(item.get("text", "")).strip()
                    if txt:
                        text_tokens.extend(txt.split())
                text_counts = pd.Series(Counter(text_tokens)).sort_values(ascending=False).head(10)

                c1_, c2_ = st.columns([1, 2])

                if not lbl_counts.empty:
                    c1_.markdown("**ê°ì²´ ë¼ë²¨ ë¶„í¬**")
                    c1_.dataframe(
                        lbl_counts.rename("ê°œìˆ˜").to_frame(),
                        use_container_width=True
                    )
                else:
                    c1_.info("ê°ì²´ ì¸ì‹ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

                # ê°ì²´ ë°•ìŠ¤ ìœ„ì¹˜ ì‹œê°í™” (ìƒìœ„ 5ê°œ)
                # ë³µë¶™í•œ ë¡œì§ ì‚¬ìš©
                def clamp(v, lo, hi):
                    return max(lo, min(hi, v))

                def safe_parse_details(raw_val):
                    if isinstance(raw_val, (dict, list)):
                        return raw_val
                    if raw_val is None:
                        return None
                    if isinstance(raw_val, str):
                        raw_val = raw_val.strip()
                        if not raw_val:
                            return None
                        try:
                            return json.loads(raw_val)
                        except json.JSONDecodeError:
                            pass
                        try:
                            return ast.literal_eval(raw_val)
                        except Exception:
                            pass
                    return raw_val

                object_details_raw = safe_parse_details(row.get("object_details", {}))
                if object_details_raw is None:
                    object_details_raw = {}
                if isinstance(object_details_raw, dict):
                    objects_list = object_details_raw.get("objects", [])
                elif isinstance(object_details_raw, list):
                    objects_list = object_details_raw
                else:
                    objects_list = []

                all_boxes = []
                for obj in objects_list:
                    if not isinstance(obj, dict):
                        continue
                    try:
                        x = float(obj.get("x", 0))
                        y = float(obj.get("y", 0))
                        w_ = float(obj.get("width", 0) or obj.get("w", 0))
                        h_ = float(obj.get("height", 0) or obj.get("h", 0))
                    except Exception:
                        continue
                    if w_ > 0 and h_ > 0:
                        all_boxes.append((x, y, w_, h_))

                if len(all_boxes) == 0:
                    c2_.caption("ê°ì²´ ë°•ìŠ¤ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    max_x = max(x+w for (x,y,w,h) in all_boxes)
                    max_y = max(y+h for (x,y,w,h) in all_boxes)
                    if max_x <= 0: max_x = 1.0
                    if max_y <= 0: max_y = 1.0

                    CANVAS_W = 1280.0
                    CANVAS_H = 720.0

                    def scale_box_any(x, y, w_, h_):
                        sx = CANVAS_W / max_x
                        sy = CANVAS_H / max_y
                        return {
                            "x": x * sx,
                            "y": y * sy,
                            "w": w_ * sx,
                            "h": h_ * sy,
                        }

                    fig, ax = plt.subplots(figsize=(6, 3.5), dpi=100)
                    ax.set_xlim([0, CANVAS_W])
                    ax.set_ylim([0, CANVAS_H])
                    ax.invert_yaxis()
                    ax.set_xticks([])
                    ax.set_yticks([])
                    ax.set_xlabel("")
                    ax.set_ylabel("")
                    used_label_positions = []

                    def get_non_overlapping_position(x, y, used_positions, min_dist=20, max_tries=20):
                        cand_x, cand_y = x, y
                        tries = 0
                        while tries < max_tries:
                            conflict = False
                            for (ux, uy) in used_positions:
                                dx = abs(cand_x - ux)
                                dy = abs(cand_y - uy)
                                if dx < min_dist and dy < min_dist:
                                    conflict = True
                                    break
                            if not conflict:
                                break
                            cand_y += 15
                            tries += 1
                        cand_x = clamp(cand_x, 0, CANVAS_W - 5)
                        cand_y = clamp(cand_y, 0, CANVAS_H - 5)
                        return cand_x, cand_y

                    sized_objects = []
                    for obj in objects_list:
                        if not isinstance(obj, dict):
                            continue
                        try:
                            ox = float(obj.get("x", 0))
                            oy = float(obj.get("y", 0))
                            ow = float(obj.get("width", 0) or obj.get("w", 0))
                            oh = float(obj.get("height", 0) or obj.get("h", 0))
                            label_val = str(obj.get("label", "obj"))
                        except Exception:
                            continue
                        if ow <= 0 or oh <= 0:
                            continue
                        area = ow * oh
                        sized_objects.append({
                            "x": ox, "y": oy, "w": ow, "h": oh,
                            "label": label_val,
                            "area": area
                        })
                    sized_objects = sorted(
                        sized_objects,
                        key=lambda d: d["area"],
                        reverse=True
                    )[:5]

                    for box in sized_objects:
                        scaled_o = scale_box_any(box["x"], box["y"], box["w"], box["h"])
                        label_txt = box["label"]
                        lw = 2.5 if label_txt.lower() == "person" else 1.5
                        ls = "--" if label_txt.lower() == "person" else "-"

                        rect_o = plt.Rectangle(
                            (scaled_o["x"], scaled_o["y"]),
                            scaled_o["w"],
                            scaled_o["h"],
                            fill=False,
                            linewidth=lw,
                            linestyle=ls
                        )
                        ax.add_patch(rect_o)

                        raw_lx = scaled_o["x"] + scaled_o["w"] + 5
                        raw_ly = scaled_o["y"] - 5
                        raw_lx = clamp(raw_lx, 0, CANVAS_W - 5)
                        raw_ly = clamp(raw_ly, 0, CANVAS_H - 5)

                        final_lx, final_ly = get_non_overlapping_position(
                            raw_lx,
                            raw_ly,
                            used_label_positions,
                            min_dist=20,
                            max_tries=20
                        )
                        used_label_positions.append((final_lx, final_ly))

                        ax.text(
                            final_lx,
                            final_ly,
                            f"[OBJ] {label_txt}",
                            fontsize=8,
                            va="top",
                            ha="left"
                        )

                    buf = io.BytesIO()
                    fig.savefig(buf, format="png", dpi=100)
                    buf.seek(0)
                    c2_.image(buf, caption="ê°ì²´ ë°°ì¹˜ ë§µ (ì •ê·œí™”ëœ ì¢Œí‘œ)", use_container_width=True)
                    plt.close(fig)

                # OCR í…ìŠ¤íŠ¸ ë‹¨ì–´ + ì‹ ë¢°ë„ í…Œì´ë¸”
                st.markdown(" ")
                st.markdown("**OCR í…ìŠ¤íŠ¸ ë‹¨ì–´ ë¹ˆë„ / ì‹ ë¢°ë„**")

                # text_details_raw ë‹¤ì‹œ íŒŒì‹±í•´ì„œ ë‹¨ì–´ë³„ ì‹ ë¢°ë„ ê³„ì‚°
                def safe_parse_details(raw_val):
                    if isinstance(raw_val, (dict, list)):
                        return raw_val
                    if raw_val is None:
                        return None
                    if isinstance(raw_val, str):
                        raw_val = raw_val.strip()
                        if not raw_val:
                            return None
                        try:
                            return json.loads(raw_val)
                        except json.JSONDecodeError:
                            pass
                        try:
                            return ast.literal_eval(raw_val)
                        except Exception:
                            pass
                    return raw_val

                text_details_list = safe_parse_details(row.get("text_details", []))
                word_conf_map = {}
                if isinstance(text_details_list, list):
                    for item in text_details_list:
                        text_val = str(item.get("text", "")).strip()
                        conf = float(item.get("probability", 0.0))
                        if not text_val:
                            continue
                        for w in text_val.split():
                            if w not in word_conf_map:
                                word_conf_map[w] = {"count": 0, "conf_sum": 0.0}
                            word_conf_map[w]["count"] += 1
                            word_conf_map[w]["conf_sum"] += conf

                if word_conf_map:
                    conf_df = pd.DataFrame([
                        {
                            "ë‹¨ì–´": w,
                            "ë¹ˆë„": v["count"],
                            "ì‹ ë¢°ë„(%)": round((v["conf_sum"] / v["count"]) * 100, 1)
                        }
                        for w, v in word_conf_map.items()
                    ])
                    conf_df = conf_df.sort_values(
                        ["ë¹ˆë„", "ì‹ ë¢°ë„(%)"],
                        ascending=[False, False]
                    ).reset_index(drop=True)
                    st.dataframe(conf_df, use_container_width=True)
                else:
                    st.info("OCR í…ìŠ¤íŠ¸ ì¸ì‹ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

                # í…ìŠ¤íŠ¸/ì‚¬ëŒ ë°°ì¹˜ ë¹„êµ (ë‚´ ì˜ìƒ vs í”¼ì–´ í‰ê· )
                st.markdown(" ")
                st.markdown("**í…ìŠ¤íŠ¸ / ì¸ë¬¼ ë°°ì¹˜ íŠ¹ì„± (ë‚´ ì˜ìƒ vs í‰ê· )**")

                if "peer_avg_dict" not in locals():
                    peer_avg_dict = {}

                bar_width = 0.35
                my_color = "#80D2FF"
                peer_color = "#5C6AFF"

                # í…ìŠ¤íŠ¸ ìœ„ì¹˜ ë¶„í¬
                c_txt_pos, c_txt_size = st.columns(2)
                with c_txt_pos:
                    text_pos_keys = ["text_left","text_middle","text_right"]
                    x_idx = range(len(text_pos_keys))
                    my_vals = [int(row.get(k, 0)) for k in text_pos_keys]
                    peer_vals = [peer_avg_dict.get(k, 0.0) for k in text_pos_keys]

                    fig, ax = plt.subplots()
                    ax.bar([i - bar_width/2 for i in x_idx], my_vals, bar_width,
                           label="ë‚´ ì˜ìƒ", color=my_color)
                    ax.bar([i + bar_width/2 for i in x_idx], peer_vals, bar_width,
                           label="í‰ê· ", color=peer_color)
                    ax.set_xticks(list(x_idx))
                    ax.set_xticklabels(["ì™¼ìª½","ì¤‘ì•™","ì˜¤ë¥¸ìª½"])
                    ax.set_ylabel("í…ìŠ¤íŠ¸ ë°•ìŠ¤ ìˆ˜")
                    ax.set_title("í…ìŠ¤íŠ¸ ìœ„ì¹˜ ë¶„í¬")
                    ax.legend()
                    st.pyplot(fig)

                with c_txt_size:
                    text_size_keys = ["text_small","text_medium","text_large"]
                    x_idx = range(len(text_size_keys))
                    my_vals = [int(row.get(k, 0)) for k in text_size_keys]
                    peer_vals = [peer_avg_dict.get(k, 0.0) for k in text_size_keys]

                    fig, ax = plt.subplots()
                    ax.bar([i - bar_width/2 for i in x_idx], my_vals, bar_width,
                           label="ë‚´ ì˜ìƒ", color=my_color)
                    ax.bar([i + bar_width/2 for i in x_idx], peer_vals, bar_width,
                           label="í‰ê· ", color=peer_color)
                    ax.set_xticks(list(x_idx))
                    ax.set_xticklabels(["ì‘ìŒ","ì¤‘ê°„","í¼"])
                    ax.set_ylabel("í…ìŠ¤íŠ¸ ë°•ìŠ¤ ìˆ˜")
                    ax.set_title("í…ìŠ¤íŠ¸ í¬ê¸° ë¶„í¬")
                    ax.legend()
                    st.pyplot(fig)

                # ì‚¬ëŒ ìœ„ì¹˜/í¬ê¸° ë¶„í¬
                c_p_pos, c_p_size = st.columns(2)
                with c_p_pos:
                    person_pos_keys = ["person_left","person_middle","person_right"]
                    x_idx = range(len(person_pos_keys))
                    my_vals = [int(row.get(k, 0)) for k in person_pos_keys]
                    peer_vals = [peer_avg_dict.get(k, 0.0) for k in person_pos_keys]

                    fig, ax = plt.subplots()
                    ax.bar([i - bar_width/2 for i in x_idx], my_vals, bar_width,
                           label="ë‚´ ì˜ìƒ", color=my_color)
                    ax.bar([i + bar_width/2 for i in x_idx], peer_vals, bar_width,
                           label="í‰ê· ", color=peer_color)
                    ax.set_xticks(list(x_idx))
                    ax.set_xticklabels(["ì™¼ìª½","ì¤‘ì•™","ì˜¤ë¥¸ìª½"])
                    ax.set_ylabel("ì‚¬ëŒ ìˆ˜")
                    ax.set_title("ì‚¬ëŒ ìœ„ì¹˜ ë¶„í¬")
                    ax.legend()
                    st.pyplot(fig)

                with c_p_size:
                    person_size_keys = ["person_small","person_medium","person_large"]
                    x_idx = range(len(person_size_keys))
                    my_vals = [int(row.get(k, 0)) for k in person_size_keys]
                    peer_vals = [peer_avg_dict.get(k, 0.0) for k in person_size_keys]

                    fig, ax = plt.subplots()
                    ax.bar([i - bar_width/2 for i in x_idx], my_vals, bar_width,
                           label="ë‚´ ì˜ìƒ", color=my_color)
                    ax.bar([i + bar_width/2 for i in x_idx], peer_vals, bar_width,
                           label="í‰ê· ", color=peer_color)
                    ax.set_xticks(list(x_idx))
                    ax.set_xticklabels(["ì‘ìŒ","ì¤‘ê°„","í¼"])
                    ax.set_ylabel("ì‚¬ëŒ ìˆ˜")
                    ax.set_title("ì‚¬ëŒ í¬ê¸° ë¶„í¬")
                    ax.legend()
                    st.pyplot(fig)

        st.markdown("---")

        # -------------------------------------
        # 5. A/B ê°œì„  ì‹œë®¬ë ˆì´ì…˜ (í•µì‹¬ ì§€í‘œ ì¡°ì •)
        # -------------------------------------
        if 'reg' in locals() and reg is not None and peer_avg_core:
            st.subheader("4. ê°œì„  ì‹œë®¬ë ˆì´ì…˜ (A/B ê°€ì´ë“œ)")

            with st.container(border=True):
                st.caption(
                    "ìœ ì‚¬ êµ¬ë…ì ì±„ë„ í‰ê·  ìˆ˜ì¤€ìœ¼ë¡œ ì¼ë¶€ ì§€í‘œ(ì œëª© ê¸¸ì´, ë°ê¸° ë“±)ë¥¼ ë§ì·„ì„ ë•Œ "
                    "ì˜ˆìƒ ì¡°íšŒìˆ˜ ë³€í™”ë¥¼ ì¶”ì •í•©ë‹ˆë‹¤."
                )

                # ì‹œë®¬ ê²°ê³¼ ìš”ì•½ KPI
                kpi_col1, kpi_col2, kpi_col3 = st.columns(3)
                kpi_col1.metric(
                    label="í˜„ì¬ ì˜ˆìƒ ì¡°íšŒìˆ˜",
                    value=(f"{current_pred_views:,}" if current_pred_views is not None else "â€”")
                )
                kpi_col2.metric(
                    label="ê°œì„  í›„ ì˜ˆìƒ ì¡°íšŒìˆ˜",
                    value=(f"{improved_pred_views:,}" if improved_pred_views is not None else "â€”"),
                    delta=(f"+{lift_abs:,}" if (lift_abs is not None and lift_abs > 0) else None)
                )
                kpi_col3.metric(
                    label="í–¥ìƒë¥ (%)",
                    value=(f"{lift_pct:.1f}%" if lift_pct is not None else "â€”"),
                    delta=(f"+{lift_pct:.1f}%" if (lift_pct is not None and lift_pct > 0) else None)
                )

                st.markdown("### ìˆ˜ì •í•˜ë©´ ì¢‹ì€ ì§€í‘œ Top 3")
                if not top_change_rows.empty:
                    for _, r in top_change_rows.iterrows():
                        render_change_row(
                            label   = get_label(r["ì§€í‘œ"]),
                            cur_val = r["í˜„ì¬ê°’"],
                            tgt_val = r["í‰ê· ê°’"],
                            gain    = r["ì¦ê°(ì˜ˆì¸¡)"]
                        )
                else:
                    st.info("ê°œì„  íš¨ê³¼ë¥¼ ì¶”ì •í•  ìˆ˜ ìˆëŠ” ì§€í‘œê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

                # ìƒì„¸ í‘œ
                st.markdown("")
                st.markdown("#### ì„¸ë¶€ ë¹„êµí‘œ")
                sims_k = []
                # sims ì¬êµ¬ì„± (ìœ„ì—ì„œ ë§Œë“  delta_views_df ê¸°ë°˜ìœ¼ë¡œ)
                if 'delta_views_df' in locals():
                    for _, row_sim in delta_views_df.iterrows():
                        sims_k.append({
                            "ì§€í‘œ": get_label(row_sim["ì§€í‘œ"]),
                            "í˜„ì¬ê°’": row_sim["í˜„ì¬ê°’"],
                            "í‰ê· ê°’": row_sim["í‰ê· ê°’"],
                            "í‰ê· ìœ¼ë¡œ ë§ì¶œ ë•Œ ì˜ˆì¸¡": row_sim["í‰ê· ìœ¼ë¡œ ë§ì¶œ ë•Œ ì˜ˆì¸¡"],
                            "ì¦ê°(ì˜ˆì¸¡)": row_sim["ì¦ê°(ì˜ˆì¸¡)"]
                        })
                if sims_k:
                    st.dataframe(pd.DataFrame(sims_k), use_container_width=True)
                else:
                    st.caption("ì„¸ë¶€ ë¹„êµ ë°ì´í„°ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    except Exception as e:
        st.exception(e)

    finally:
        if 'tmp_path' in locals() and tmp_path and os.path.exists(tmp_path):
            try:
                os.remove(tmp_path)
            except Exception:
                pass
