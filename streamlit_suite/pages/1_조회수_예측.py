# -*- coding: utf-8 -*-
import os, sys, tempfile, json
import numpy as np
import pandas as pd
import streamlit as st
import io
from collections import Counter
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
plt.rcParams['font.family'] = 'Malgun Gothic'   # í•œê¸€ í°íŠ¸
plt.rcParams['axes.unicode_minus'] = False      # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€

# =============== ê²½ë¡œ/ëª¨ë“ˆ ë¡œë“œ ===============
WEB_DIR = r"C:\web"  # í•„ìš” ì‹œ ìˆ˜ì •
if WEB_DIR not in sys.path:
    sys.path.append(WEB_DIR)

try:
    from feature import process_user_input
except Exception as e:
    st.set_page_config(page_title="TubeBoost", layout="wide")
    st.error(f"feature.py import ì‹¤íŒ¨: {e}")
    st.stop()

st.set_page_config(page_title="ì¡°íšŒìˆ˜ ì˜ˆì¸¡", layout="wide")
st.title("ğŸ“ˆ ì¡°íšŒìˆ˜ ì˜ˆì¸¡")

# =============== ìœ í‹¸ ===============
FEATURE_LABELS = {
    "title_length": "ì œëª© ê¸¸ì´",
    "word_count": "ì œëª© ë‹¨ì–´ ìˆ˜",
    "emoji_count": "ì œëª© ì´ëª¨ì§€ ìˆ˜",
    "special_char_count": "íŠ¹ìˆ˜ë¬¸ì ìˆ˜",
    "person_count": "ì¸ë„¤ì¼ ì‚¬ëŒ ìˆ˜",
    "object_count": "ì¸ë„¤ì¼ ê°ì²´ ìˆ˜",
    "has_text": "ì¸ë„¤ì¼ í…ìŠ¤íŠ¸ í¬í•¨ ì—¬ë¶€",
    "brightness": "ì¸ë„¤ì¼ ë°ê¸°",
    "contrast": "ì¸ë„¤ì¼ ëŒ€ë¹„",
    "has_question_mark": "ì œëª© ? í¬í•¨ ì—¬ë¶€",
    "has_exclamation": "ì œëª© ! í¬í•¨ ì—¬ë¶€",
    "duration": "ì˜ìƒ ê¸¸ì´",
}
def get_label(k: str) -> str:
    """ì˜ë¬¸ featureëª…ì„ í•œêµ­ì–´ë¡œ ë³€í™˜"""
    return FEATURE_LABELS.get(k, k)

def _safe_mean(series_like):
    try:
        return float(pd.to_numeric(series_like, errors="coerce").mean())
    except Exception:
        return np.nan

def _predict_views_by_regressor(model, df, cols):
    pred = model.predict(df[cols].values)
    # ë¡œê·¸ ìŠ¤ì¼€ì¼ í•™ìŠµì´ì—ˆë‹¤ë©´ expm1, ì•„ë‹ˆë¼ë©´ ìƒëµ
    try:
        return int(np.expm1(pred[0]))
    except Exception:
        try:
            return int(float(pred[0]))
        except Exception:
            return None

def load_csv_compat(path: str) -> pd.DataFrame:
    """pandas ë²„ì „/ì¸ì½”ë”© ì´ìŠˆë¥¼ í”¼í•´ì„œ ì•ˆì „í•˜ê²Œ CSVë¥¼ ì½ëŠ”ë‹¤."""
    encodings = ["utf-8", "utf-8-sig", "cp949", "euc-kr", "latin1"]
    engines = ["c", "python"]
    last_err = None
    for enc in encodings:
        for eng in engines:
            try:
                with open(path, "r", encoding=enc, errors="ignore") as f:
                    return pd.read_csv(f, engine=eng)
            except Exception as e:
                last_err = e
                continue
    raise last_err if last_err else FileNotFoundError(path)

def parse_object_labels(obj_details):
    """object_details(dict/list/str)ì—ì„œ ë¼ë²¨ ë¶„í¬ ì¶”ì¶œ"""
    try:
        v = obj_details
        if isinstance(v, str):
            v = json.loads(v)
    except Exception:
        try:
            import ast
            v = ast.literal_eval(obj_details)
        except Exception:
            v = {}
    if isinstance(v, dict):
        objs = v.get("objects", [])
    elif isinstance(v, list):
        objs = v
    else:
        objs = []
    labels = [o.get("label", "unknown") for o in objs if isinstance(o, dict)]
    if not labels:
        return pd.Series(dtype=int)
    return pd.Series(labels).value_counts().sort_values(ascending=False)

def extract_text_samples(text_details, topk=5):
    """text_details(list/str)ì—ì„œ í™•ë¥  ë†’ì€ í…ìŠ¤íŠ¸ ìƒ˜í”Œ ì¶”ì¶œ"""
    try:
        v = text_details
        if isinstance(v, str):
            v = json.loads(v)
    except Exception:
        try:
            import ast
            v = ast.literal_eval(text_details)
        except Exception:
            v = []
    rows = []
    for t in v if isinstance(v, list) else []:
        txt = t.get("text", "")
        prob = float(t.get("probability", 0.0))
        rows.append((prob, txt))
    rows.sort(key=lambda x: x[0], reverse=True)
    return [f"{txt} (p={prob:.2f})" for prob, txt in rows[:topk] if txt]

def chip(text: str):
    return f"""<span style="display:inline-block;padding:4px 10px;margin:4px;border-radius:999px;background:#F1F5F9;border:1px solid #E2E8F0;font-size:12px">{text}</span>"""

def color_chip(name: str):
    # ê°„ë‹¨ ë§¤í•‘ (Streamlitì—ì„œ CSS ì´ë¦„ ëŒ€ë¶€ë¶„ ë Œë” ê°€ëŠ¥)
    bg = name
    return f"""<span style="display:inline-block;padding:6px 12px;margin:4px;border-radius:10px;border:1px solid #e5e7eb;background:{bg};color:#111827;font-weight:600">{name}</span>"""

def metric_row(df_row, cols, title):
    vals = [(k, df_row.get(k, 0)) for k in cols]
    table = pd.DataFrame({"ì§€í‘œ": [k for k,_ in vals],
                          "ê°’":  [vals[i][1] for i in range(len(vals))]})
    st.subheader(title)
    st.dataframe(table, use_container_width=True)
    
def get_peer_subset(md: pd.DataFrame, my_subs: int, pct: float, min_rows: int = 100) -> pd.DataFrame:
    """
    mdì—ì„œ ë‚´ êµ¬ë…ììˆ˜ì™€ Â±pct% ì´ë‚´ì¸ í–‰ë§Œ ì¶”ì¶œ.
    í‘œë³¸ ìˆ˜ê°€ min_rows ë¯¸ë§Œì´ë©´ ë²”ìœ„ë¥¼ ì ì§„ì ìœ¼ë¡œ í™•ëŒ€(ìµœëŒ€ Â±50%).
    """
    if "subscriber_count" not in md.columns:
        return pd.DataFrame()
    subs = pd.to_numeric(md["subscriber_count"], errors="coerce")
    md2 = md.copy()
    md2["subscriber_count"] = subs

    # ì´ˆê¸° ë²”ìœ„
    p = max(0.01, pct / 100.0)
    my = float(my_subs)
    lo, hi = my * (1 - p), my * (1 + p)

    # ì ì§„ í™•ì¥
    for _ in range(10):  # ìµœëŒ€ 10ë²ˆ(ëŒ€ëµ Â±50%ê¹Œì§€)
        peer = md2[(md2["subscriber_count"] >= lo) & (md2["subscriber_count"] <= hi)]
        if len(peer) >= min_rows or p >= 0.5:
            return peer
        p *= 1.25
        lo, hi = my * (1 - p), my * (1 + p)
    return peer
def plot_sensitivity_barh(delta_df: pd.DataFrame, topn: int = 5, title: str = ""):
    """
    delta_df: columns => ['ì§€í‘œ','ì¦ê°(ì˜ˆì¸¡)']
    topnê°œ ìƒìœ„ ì§€í‘œë¥¼ ê°€ë¡œ ë§‰ëŒ€ ê·¸ë˜í”„ë¡œ ê·¸ë¦°ë‹¤.
    """
    if delta_df is None or delta_df.empty or "ì¦ê°(ì˜ˆì¸¡)" not in delta_df.columns:
        return

    plot_df = (
        delta_df.dropna(subset=["ì¦ê°(ì˜ˆì¸¡)"])
                .sort_values("ì¦ê°(ì˜ˆì¸¡)", ascending=False)
                .head(topn)
    )
    if plot_df.empty:
        return

    fig, ax = plt.subplots(figsize=(6, 3))
    colors = ["#80D2FF" if v > 0 else "#E57373" for v in plot_df["ì¦ê°(ì˜ˆì¸¡)"]]

    ax.barh(plot_df["ì§€í‘œ"], plot_df["ì¦ê°(ì˜ˆì¸¡)"], color=colors)
    ax.invert_yaxis()
    ax.axvline(0, color="gray", lw=1)
    ax.set_title(title)

    for i, v in enumerate(plot_df["ì¦ê°(ì˜ˆì¸¡)"]):
        ax.text(
            v + (0.02 * max(plot_df["ì¦ê°(ì˜ˆì¸¡)"].max(), 1)),
            i,
            f"{int(v):+}",
            va="center",
            ha="left" if v >= 0 else "right",
            fontsize=8,
        )

    st.pyplot(fig)
    
def render_change_row(label, cur_val, tgt_val, gain=None):
    """
    label: ì§€í‘œ ì´ë¦„(str)
    cur_val: í˜„ì¬ ê°’
    tgt_val: ì¶”ì²œ/í‰ê·  ê°’
    gain: ì˜ˆìƒ ì¡°íšŒìˆ˜ ì¦ê°€ëŸ‰ (ì •ìˆ˜ or None)
    """
    diff=float(cur_val)-float(tgt_val)
    arrow = "â¡ï¸"
    gain_txt = ""
    if gain is not None:
        if gain > 0:
            gain_txt = f"<span style='color:#16a34a;font-weight:600;'>+{gain:,}â†‘</span>"
        elif gain < 0:
            gain_txt = f"<span style='color:#dc2626;font-weight:600;'>{gain:,}â†“</span>"
    
    if abs(diff) < 1e-6:
        # ê±°ì˜ ë™ì¼
        base_phrase = "ê°€ í‰ê· ê³¼ ìœ ì‚¬í•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤."
    else:
        if diff > 0:
            # í˜„ì¬ê°’ì´ ë” í¼
            if "ê¸¸ì´" in label:
                base_phrase = "ê°€ ê¸´ í¸ì…ë‹ˆë‹¤."
            elif "ìˆ˜" in label:
                base_phrase = "ê°€ ë§ì€ í¸ì…ë‹ˆë‹¤."
            elif "ë°ê¸°" in label or "ëŒ€ë¹„" in label:
                base_phrase = "ê°€ ë†’ì€ í¸ì…ë‹ˆë‹¤."
            else:
                base_phrase = "ê°€ ë†’ì€ í¸ì…ë‹ˆë‹¤."
        else:
            # í˜„ì¬ê°’ì´ ë” ì‘ìŒ
            if "ê¸¸ì´" in label:
                base_phrase = "ê°€ ì§§ì€ í¸ì…ë‹ˆë‹¤."
            elif "ìˆ˜" in label:
                base_phrase = "ê°€ ì ì€ í¸ì…ë‹ˆë‹¤."
            elif "ë°ê¸°" in label or "ëŒ€ë¹„" in label:
                base_phrase = "ê°€ ë‚®ì€ í¸ì…ë‹ˆë‹¤."
            else:
                base_phrase = "ê°€ ë‚®ì€ í¸ì…ë‹ˆë‹¤."
                
    st.markdown(
        f"""
        <div style="
            border:1px solid #e5e7eb;
            border-radius:10px;
            padding:8px 12px;
            margin-bottom:6px;
            background:#f9fafb;
            font-size:18px;
            line-height:2;
        ">
            <div style="font-weight:600; color:#111827;">{label}
            <span style="font-weigth:300;">{base_phrase}</span>
            </div>
            <div style="color:#374151;">
                <span style="color:#4b5563;"> í˜„ì¬ </span>
                <strong style="color:#111827;"> {cur_val:.1f} </strong>
                {arrow}
                <span style="color:#4b5563;"> ì¶”ì²œ </span>
                <strong style="color:#111827;"> {tgt_val:.1f} </strong>
                {("&nbsp; &nbsp; &nbsp;" + gain_txt) if gain_txt else ""}
            </div>
        </div>
        """,
        unsafe_allow_html=True
    )



# =============== ì‚¬ì´ë“œë°” ===============
with st.sidebar:
    st.subheader("êµ¬ë…ììˆ˜ ë²”ìœ„ ì„¤ì •")
    peer_pct = st.slider("êµ¬ë…ì ë²”ìœ„(Â±%)", min_value=1, max_value=50, value=15, step=1,
                     help="ë‚´ êµ¬ë…ì ìˆ˜ì˜ Â±ë²”ìœ„ë¡œ ìœ ì‚¬ êµ¬ë…ì ì±„ë„ì„ ì„ íƒí•©ë‹ˆë‹¤.")
    peer_min_rows = st.number_input("ìµœì†Œ í‘œë³¸ ìˆ˜", min_value=20, value=100, step=10,
                                    help="ë²”ìœ„ ë‚´ í‘œë³¸ì´ ë¶€ì¡±í•˜ë©´ ìë™ìœ¼ë¡œ ë²”ìœ„ë¥¼ ë„“í™ë‹ˆë‹¤.")
    st.divider()
    st.subheader("ëª¨ë¸/ë°ì´í„° ê²½ë¡œ")
    saved_models_dir = st.text_input("saved_models ê²½ë¡œ", value=os.path.join(WEB_DIR, "saved_models"))
    model_datas_path = st.text_input("model_datas.csv ê²½ë¡œ", value=os.path.join(WEB_DIR, "model_datas.csv"))

# =============== ì…ë ¥ í¼ ===============
with st.form("predict_form"):
    c1, c2 = st.columns([3, 2])
    with c1:
        title = st.text_input("ì œëª©", value="ì¸ìƒì—¬í–‰ì§€ì˜€ë˜ ë‰´ìš•ì— ë‹¤ì‹œ í˜¼ì ì…ì¥! ê·¼ë° ì™œ ì´ë ‡ê²Œ ë³€í•¨...? (ì° ë‰´ìš”ì»¤ê°€ ì¶”ì²œí•´ì¤€ ë¹µì§‘, ë§›ì§‘, ì¹´í˜ ë‹¤ ë¿Œì‹œê¸´í•¨ã…£ìŠ¤í‚´ìŠ¤ ì—‰ë½• ëŒ€ë‚œë¦¬)")
        thumbnail_url = st.text_input("ì¸ë„¤ì¼ URL", value="https://i.ytimg.com/vi/D-jOG2ybV1s/hq720.jpg")
        thumbnail_file = st.file_uploader("ë˜ëŠ” ì´ë¯¸ì§€ ì—…ë¡œë“œ", type=["png","jpg","jpeg","webp"])
    with c2:
        duration = st.text_input("ì˜ìƒ ê¸¸ì´ (MM:SS)", value="36:40")
        subscriber = st.number_input("êµ¬ë…ì ìˆ˜", min_value=0, value=230000, step=1000)
        total_videos = st.number_input("ëˆ„ì  ì—…ë¡œë“œ ìˆ˜", min_value=0, value=600, step=1)
        category = st.text_input("ì¹´í…Œê³ ë¦¬", value="General")
    run = st.form_submit_button("ì˜ˆì¸¡ ì‹¤í–‰")

# =============== ì‹¤í–‰ ===============
if run:
    # 1) ì¸ë„¤ì¼ ì¸í’‹ ì •ë¦¬
    tmp_path = None
    if thumbnail_url.strip():
        thumb_input = thumbnail_url.strip()
    elif thumbnail_file is not None:
        suffix = os.path.splitext(thumbnail_file.name)[1].lower() or ".jpg"
        fd, tmp_path = tempfile.mkstemp(suffix=suffix)
        os.close(fd)
        with open(tmp_path, "wb") as f:
            f.write(thumbnail_file.read())
        thumb_input = tmp_path
    else:
        st.error("ì¸ë„¤ì¼ URLì„ ì…ë ¥í•˜ê±°ë‚˜ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        st.stop()

    try:
        # 2) feature.pyë¡œ í”¼ì²˜ ìƒì„± + í´ëŸ¬ìŠ¤í„° ì˜ˆì¸¡
        df, cluster = process_user_input(
            title, thumb_input, duration, subscriber, total_videos, category
        )
        row = df.iloc[0].to_dict()

        

        # 3) (ì„ íƒ) í´ëŸ¬ìŠ¤í„°ë³„ íšŒê·€ëª¨ë¸ë¡œ ì¡°íšŒìˆ˜ ì˜ˆì¸¡
        predicted_views = None
        feat_cols = [
            'duration','subscriber_count','brightness','contrast',
            'title_length','word_count','emoji_count','special_char_count',
            'is_clickbait','has_question_mark','has_exclamation',
            'pub_year','pub_month','pub_weekday',
            'color_red','color_blue','color_green','color_yellow',
            'color_purple','color_brown','color_grey','color_white','color_pink',
            'person_count','object_count','has_text',
            'person_left','person_middle','person_right',
            'person_small','person_medium','person_large',
            'text_left','text_middle','text_right',
            'text_small','text_medium','text_large'
        ]
        for c in feat_cols:
            if c not in df.columns:
                df[c] = 0

        import joblib
        reg, cluster_mean, cluster_top10_mean = None, None, None
        model_path = os.path.join(saved_models_dir, f"model_cluster_{cluster}.pkl")
        if os.path.exists(model_path):
            try:
                reg = joblib.load(model_path)
                predicted_views = _predict_views_by_regressor(reg, df, feat_cols)
            except Exception as e:
                st.warning(f"íšŒê·€ ëª¨ë¸ ë¡œë”©/ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")

        # 4) í´ëŸ¬ìŠ¤í„° í†µê³„ (í‰ê· /ìƒìœ„10%)
        md = None
        if os.path.exists(model_datas_path):
            try:
                md = load_csv_compat(model_datas_path)
                # cluster ì»¬ëŸ¼ì´ ë¬¸ìì—´ì¼ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ ìˆ«ìí™”
                md["cluster"] = pd.to_numeric(md.get("cluster"), errors="coerce")
                filt = md[md["cluster"] == cluster]
                if len(filt):
                    cluster_mean = int(_safe_mean(filt.get("view_count")))
                    top10 = filt.nlargest(max(1, int(len(filt)*0.1)), "view_count")
                    cluster_top10_mean = int(_safe_mean(top10.get("view_count")))
            except Exception as e:
                st.warning(f"model_datas.csv ì½ê¸° ì‹¤íŒ¨: {e}")
                
                
                # === í”¼ì–´ ê·¸ë£¹(ìœ ì‚¬ êµ¬ë…ì) í‰ê·  ===
        peer_mean_views = None
        peer_top10_mean_views = None
        peer_avg_core = None

        if md is not None and len(md):
            peer_df = get_peer_subset(md, int(row.get("subscriber_count", 0)), peer_pct, peer_min_rows)
            if len(peer_df):
                # ì¡°íšŒìˆ˜ í‰ê· ë“¤
                if "view_count" in peer_df.columns:
                    peer_mean_views = int(_safe_mean(peer_df["view_count"]))
                    top10_peer = peer_df.nlargest(max(1, int(len(peer_df) * 0.1)), "view_count")
                    peer_top10_mean_views = int(_safe_mean(top10_peer["view_count"]))

                # ì½”ì–´ í”¼ì²˜ í‰ê· 
                core_cols = [
                    "duration","title_length","word_count","emoji_count","special_char_count",
                    "has_question_mark","has_exclamation","brightness","contrast",
                    "person_count","object_count","has_text"
                ]
                peer_avg_core = {}
                for c in core_cols:
                    if c in peer_df.columns:
                        peer_avg_core[c] = round(_safe_mean(peer_df[c]), 3)
                        
                dist_cols = [
                    "text_left","text_middle","text_right",
                    "text_small","text_medium","text_large",
                    "person_left","person_middle","person_right",
                    "person_small","person_medium","person_large",
                ]

                peer_avg_dict = {}
                for c in dist_cols:
                    if c in peer_df.columns:
                        peer_avg_dict[c] = float(_safe_mean(peer_df[c]))
                    else:
                        peer_avg_dict[c] = 0.0  # ì—†ëŠ” ì»¬ëŸ¼ì€ 0ìœ¼ë¡œ ì±„ì›Œë„ ì•ˆì „

        # === ì‹œë®¬ë ˆì´ì…˜ ë¯¸ë¦¬ ê³„ì‚° ===
        current_pred_views, improved_pred_views, lift_abs, lift_pct = None, None, None, None
        top_change_rows, drivers_text = pd.DataFrame(), ""

        if reg is not None and peer_avg_core:
            def simulate(modified):
                new_df = df.copy()
                for k, v in modified.items():
                    new_df.at[0, k] = v
                return _predict_views_by_regressor(reg, new_df, feat_cols)

            sims = []
            target_keys = [
                'title_length','emoji_count','special_char_count','person_count','has_text',
                'brightness','contrast','word_count','object_count'
            ]
            for k in target_keys:
                if k not in peer_avg_core:
                    continue
                cur_val = float(df.iloc[0].get(k, 0))
                peer_val = float(peer_avg_core[k])
                if k in ['emoji_count','special_char_count','person_count','has_text','word_count','object_count','title_length']:
                    peer_val = int(round(peer_val))
                pred_peer = simulate({k: peer_val})
                diff_val = None
                if predicted_views and pred_peer:
                    diff_val = int(pred_peer) - int(predicted_views)
                sims.append({"ì§€í‘œ":k,"í˜„ì¬ê°’":cur_val,"í‰ê· ê°’":peer_val,"í‰ê· ìœ¼ë¡œ ë§ì¶œ ë•Œ ì˜ˆì¸¡":pred_peer,"ì¦ê°(ì˜ˆì¸¡)":diff_val})
            delta_views_df = pd.DataFrame(sims)

            improving_changes = {r["ì§€í‘œ"]:r["í‰ê· ê°’"] for _,r in delta_views_df.iterrows() if r["ì¦ê°(ì˜ˆì¸¡)"] and r["ì¦ê°(ì˜ˆì¸¡)"]>0}
            pred_combo = simulate(improving_changes) if improving_changes else None
            current_pred_views = int(predicted_views) if predicted_views else None
            improved_pred_views = int(pred_combo) if pred_combo else None
            if current_pred_views and improved_pred_views:
                lift_abs = improved_pred_views - current_pred_views
                lift_pct = (lift_abs / current_pred_views) * 100 if current_pred_views>0 else None
            top_change_rows = delta_views_df.dropna(subset=["ì¦ê°(ì˜ˆì¸¡)"]).sort_values("ì¦ê°(ì˜ˆì¸¡)",ascending=False).head(3)
            drivers_text = ", ".join(get_label(v) for v in top_change_rows["ì§€í‘œ"].tolist()) if not top_change_rows.empty else ""


        st.success(f"ë¶„ì„ì´ ì™„ë£ŒëìŠµë‹ˆë‹¤. í´ëŸ¬ìŠ¤í„° {cluster}ê°€ ì ìš©ë©ë‹ˆë‹¤.")
        st.markdown(" ")
        
        # ìƒë‹¨ ìš”ì•½ + ì¸ë„¤ì¼ í”„ë¦¬ë·°
        cA, cB = st.columns([3, 2])
        with cA:
            
            st.markdown("### ğŸ“Œ ì¸ì‚¬ì´íŠ¸ ìš”ì•½")
            st.markdown(" ")

            summary_lines = []
            if current_pred_views:
                summary_lines.append(f"í˜„ì¬ êµ¬ì„±ìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ì¡°íšŒìˆ˜ëŠ” ì•½ {current_pred_views:,}íšŒì…ë‹ˆë‹¤.")
            if improved_pred_views and lift_abs and lift_pct:
                summary_lines.append(f"í•µì‹¬ ì§€í‘œë¥¼ í‰ê·  ìˆ˜ì¤€ìœ¼ë¡œ ì¡°ì •í•˜ë©´ ì•½ {improved_pred_views:,}íšŒê¹Œì§€ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            if drivers_text:
                summary_lines.append(f"íŠ¹íˆ {drivers_text}ê°€ ì¡°íšŒìˆ˜ì— í° ì˜í–¥ì„ ì£¼ëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.")
            st.write("\n".join(f"\n{s}" for s in summary_lines))

        with cB:
            try:
                st.image(thumb_input, caption="ì…ë ¥ ì¸ë„¤ì¼", use_container_width=True)
            except Exception:
                pass
            
        # 6) ì œëª© ë¶„ì„ ì˜ì—­ â€” ë” ë§ì€ ì§€í‘œ
        st.markdown("---")
        st.header("ğŸ“ ì œëª© ë¶„ì„")
        tcol1, tcol2, tcol3 = st.columns([1,1,1])
        tcol1.metric("ì œëª© ê¸¸ì´", int(row.get("title_length", 0)))
        tcol2.metric("ë‹¨ì–´ ìˆ˜", int(row.get("word_count", 0)))
        tcol3.metric("íŠ¹ìˆ˜ë¬¸ì ìˆ˜", int(row.get("special_char_count", 0)))

        tcol1.metric("ì´ëª¨ì§€ ìˆ˜", int(row.get("emoji_count", 0)))
        tcol2.metric("? í¬í•¨", "Yes" if int(row.get("has_question_mark", 0)) else "No")
        tcol3.metric("! í¬í•¨", "Yes" if int(row.get("has_exclamation", 0)) else "No")

        # top_noun chips
        nouns = [row.get("top_noun_1",""), row.get("top_noun_2",""), row.get("top_noun_3","")]
        nouns = [n for n in nouns if str(n).strip()]
        if nouns:
            st.markdown("**ìƒìœ„ ëª…ì‚¬(Top Nouns)**", help="ì œëª©ì—ì„œ ì¶”ì¶œí•œ ì£¼ìš” ëª…ì‚¬ 3ê°œ")
            st.markdown("".join(chip(n) for n in nouns), unsafe_allow_html=True)

        # 7) ì¸ë„¤ì¼ ë¶„ì„ â€” ìƒ‰ìƒ/ë°ê¸°/ëŒ€ë¹„/ê°ì²´/í…ìŠ¤íŠ¸
        st.markdown("---")
        st.header("ğŸ–¼ï¸ ì¸ë„¤ì¼ ë¶„ì„")

        scol1, scol2, scol3 = st.columns([1,1,1])
        scol1.metric("ë°ê¸°", f"{float(row.get('brightness',0)):.1f}")
        scol2.metric("ëŒ€ë¹„",  f"{float(row.get('contrast',0)):.1f}")
        scol3.metric("í…ìŠ¤íŠ¸ ì¡´ì¬", "Yes" if int(row.get("has_text", 0)) else "No")

        scol1.metric("ì‚¬ëŒ ìˆ˜", int(row.get("person_count", 0)))
        scol2.metric("ê°ì²´ ìˆ˜", int(row.get("object_count", 0)))
        try:
            h, w = row.get("thumbnail_size", (None,None))
            scol3.metric("ì´ë¯¸ì§€ í¬ê¸°", f"{w}Ã—{h}" if h and w else "â€”")
        except Exception:
            pass

        # dominant colors â†’ ì¹©
        st.markdown("**ì£¼ìš” ìƒ‰ìƒ**")
        dom_colors = []
        if isinstance(row.get("dominant_colors"), str):
            dom_colors = [c.strip() for c in row["dominant_colors"].split(",") if c.strip()]
        if dom_colors:
            st.markdown("".join(color_chip(c) for c in dom_colors), unsafe_allow_html=True)

        # ê°ì²´ ë¼ë²¨ / í…ìŠ¤íŠ¸ ë¶„í¬ ì‹œê°í™”
        lbl_counts = parse_object_labels(row.get("object_details", {}))
        text_details_raw = row.get("text_details", [])
        if isinstance(text_details_raw, str):
            import ast
            try:
                text_details_raw = ast.literal_eval(text_details_raw)
            except Exception:
                text_details_raw = []

        # OCR í…ìŠ¤íŠ¸ì—ì„œ ë‹¨ì–´ë³„ ë¹ˆë„ ì¶”ì¶œ
        from collections import Counter
        text_tokens = []
        for item in text_details_raw:
            txt = str(item.get("text", "")).strip()
            if txt:
                text_tokens.extend(txt.split())

        text_counts = pd.Series(Counter(text_tokens)).sort_values(ascending=False).head(10)

        
        st.markdown(" ")
        with st.expander("ğŸ” ì¸ë„¤ì¼ ì§€í‘œ ë” ì•Œì•„ë³´ê¸°"):
            # ë‘ ê°œì˜ ì—´ë¡œ ë°°ì¹˜
            c1, c2 = st.columns([1, 2])

            # --- ê°ì²´ ë¼ë²¨ ë¶„í¬ ---
            if not lbl_counts.empty:
                c1.markdown("**ê°ì²´ ë¼ë²¨ ë¶„í¬**")
                c1.dataframe(lbl_counts.rename("ê°œìˆ˜").to_frame(), use_container_width=True)
            else:
                c1.info("ê°ì²´ ì¸ì‹ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

            def safe_parse_details(raw_val):
                import ast, json
                out = raw_val
                if isinstance(out, str):
                    try:
                        out = ast.literal_eval(out)
                    except Exception:
                        try:
                            out = json.loads(out)
                        except Exception:
                            out = None
                return out

            def clamp(v, lo, hi):
                return max(lo, min(hi, v))

            # 1) object_detailsë§Œ ì‚¬ìš©
            object_details_raw = safe_parse_details(row.get("object_details", {}))
            if object_details_raw is None:
                object_details_raw = {}
            if isinstance(object_details_raw, dict):
                objects_list = object_details_raw.get("objects", [])
            elif isinstance(object_details_raw, list):
                objects_list = object_details_raw
            else:
                objects_list = []

            # 2) ì¢Œí‘œê³„ í¬ê¸° ì¶”ì • (ê°ì²´ë§Œìœ¼ë¡œ)
            all_boxes = []
            for obj in objects_list:
                if not isinstance(obj, dict):
                    continue
                try:
                    x = float(obj.get("x", 0))
                    y = float(obj.get("y", 0))
                    w = float(obj.get("width", 0) or obj.get("w", 0))
                    h = float(obj.get("height", 0) or obj.get("h", 0))
                except Exception:
                    continue
                if w > 0 and h > 0:
                    all_boxes.append((x, y, w, h))

            if len(all_boxes) == 0:
                c2.caption("ê°ì²´ ë°•ìŠ¤ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                max_x = max(x+w for (x,y,w,h) in all_boxes)
                max_y = max(y+h for (x,y,w,h) in all_boxes)
                if max_x <= 0: max_x = 1.0
                if max_y <= 0: max_y = 1.0

                CANVAS_W = 1280.0
                CANVAS_H = 720.0

                def scale_box_any(x, y, w, h):
                    sx = CANVAS_W / max_x
                    sy = CANVAS_H / max_y
                    return {
                        "x": x * sx,
                        "y": y * sy,
                        "w": w * sx,
                        "h": h * sy,
                    }

                # figure
                fig, ax = plt.subplots(figsize=(6, 3.5), dpi=100)
                ax.set_xlim([0, CANVAS_W])
                ax.set_ylim([0, CANVAS_H])
                ax.invert_yaxis()
                ax.set_xticks([])
                ax.set_yticks([])
                ax.set_xlabel("")
                ax.set_ylabel("")

                used_label_positions = []

                def get_non_overlapping_position(x, y, used_positions, min_dist=20, max_tries=20):
                    cand_x, cand_y = x, y
                    tries = 0
                    while tries < max_tries:
                        conflict = False
                        for (ux, uy) in used_positions:
                            dx = abs(cand_x - ux)
                            dy = abs(cand_y - uy)
                            if dx < min_dist and dy < min_dist:
                                conflict = True
                                break
                        if not conflict:
                            break
                        cand_y += 15
                        tries += 1
                    cand_x = clamp(cand_x, 0, CANVAS_W - 5)
                    cand_y = clamp(cand_y, 0, CANVAS_H - 5)
                    return cand_x, cand_y

                # ë©´ì  TOP5
                sized_objects = []
                for obj in objects_list:
                    if not isinstance(obj, dict):
                        continue
                    try:
                        ox = float(obj.get("x", 0))
                        oy = float(obj.get("y", 0))
                        ow = float(obj.get("width", 0) or obj.get("w", 0))
                        oh = float(obj.get("height", 0) or obj.get("h", 0))
                        label_val = str(obj.get("label", "obj"))
                    except Exception:
                        continue
                    if ow <= 0 or oh <= 0:
                        continue
                    area = ow * oh
                    sized_objects.append({
                        "x": ox, "y": oy, "w": ow, "h": oh,
                        "label": label_val,
                        "area": area
                    })

                sized_objects = sorted(sized_objects, key=lambda d: d["area"], reverse=True)[:5]

                for box in sized_objects:
                    scaled_o = scale_box_any(box["x"], box["y"], box["w"], box["h"])

                    label_txt = box["label"]
                    lw = 2.5 if label_txt.lower() == "person" else 1.5
                    ls = "--" if label_txt.lower() == "person" else "-"

                    rect_o = plt.Rectangle(
                        (scaled_o["x"], scaled_o["y"]),
                        scaled_o["w"],
                        scaled_o["h"],
                        fill=False,
                        linewidth=lw,
                        linestyle=ls
                    )
                    ax.add_patch(rect_o)

                    raw_lx = scaled_o["x"] + scaled_o["w"] + 5
                    raw_ly = scaled_o["y"] - 5
                    raw_lx = clamp(raw_lx, 0, CANVAS_W - 5)
                    raw_ly = clamp(raw_ly, 0, CANVAS_H - 5)

                    final_lx, final_ly = get_non_overlapping_position(
                        raw_lx,
                        raw_ly,
                        used_label_positions,
                        min_dist=20,
                        max_tries=20
                    )
                    used_label_positions.append((final_lx, final_ly))

                    ax.text(
                        final_lx,
                        final_ly,
                        f"[OBJ] {label_txt}",
                        fontsize=8,
                        va="top",
                        ha="left"
                    )

                buf = io.BytesIO()
                fig.savefig(buf, format="png", dpi=100)
                buf.seek(0)
                c2.image(buf, caption="ê°ì²´ ë°°ì¹˜ ë§µ (ì •ê·œí™”ëœ ì¢Œí‘œ)", use_container_width=True)
                plt.close(fig)

            def safe_parse_details(raw_val):
                """
                ë¬¸ìì—´, dict, list í˜•íƒœì˜ ì…ë ¥ì„ ì•ˆì „í•˜ê²Œ íŒŒì‹±í•˜ì—¬ Python ê°ì²´ë¡œ ë°˜í™˜.
                JSON, literal_eval, ì›ë³¸ í˜•íƒœë¥¼ ëª¨ë‘ ì§€ì›.
                ì‹¤íŒ¨ ì‹œ None ë°˜í™˜.
                """
                # ì´ë¯¸ dictë‚˜ listë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
                if isinstance(raw_val, (dict, list)):
                    return raw_val

                # ë¹„ì–´ìˆê±°ë‚˜ Noneì´ë©´ None ë°˜í™˜
                if raw_val is None:
                    return None

                # ë¬¸ìì—´ì¼ ê²½ìš° JSON ë˜ëŠ” Python literal í˜•íƒœ ì‹œë„
                if isinstance(raw_val, str):
                    raw_val = raw_val.strip()
                    if not raw_val:
                        return None

                    # JSON í˜•ì‹ ì‹œë„
                    try:
                        return json.loads(raw_val)
                    except json.JSONDecodeError:
                        pass

                    # literal_eval (ex: "[{'text':'Hi'}]" ê°™ì€ Python literal)
                    try:
                        return ast.literal_eval(raw_val)
                    except Exception:
                        pass

                # ê·¸ ì™¸ íƒ€ì…ì€ ê·¸ëŒ€ë¡œ ë°˜í™˜ (ì˜ˆ: int, float ë“±)
                return raw_val


            # --- í…ìŠ¤íŠ¸ ë‹¨ì–´ ë¶„í¬ ---
            if not text_counts.empty:
                st.markdown("**OCR í…ìŠ¤íŠ¸ ë‹¨ì–´**")

                # text_details_raw ì•ˆì—ì„œ ë‹¨ì–´ë³„ í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
                text_details_raw = safe_parse_details(row.get("text_details", []))
                word_conf_map = {}
                if isinstance(text_details_raw, list):
                    for item in text_details_raw:
                        text = str(item.get("text", "")).strip()
                        conf = float(item.get("probability", 0.0))
                        if not text:
                            continue
                        # ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
                        for w in text.split():
                            if w not in word_conf_map:
                                word_conf_map[w] = {"count": 0, "conf_sum": 0.0}
                            word_conf_map[w]["count"] += 1
                            word_conf_map[w]["conf_sum"] += conf

                if word_conf_map:
                    conf_df = pd.DataFrame([
                        {
                            "ë‹¨ì–´": w,
                            "ë¹ˆë„": v["count"],
                            "ì‹ ë¢°ë„(%)": round((v["conf_sum"] / v["count"]) * 100, 1)
                        }
                        for w, v in word_conf_map.items()
                    ])
                    conf_df = conf_df.sort_values(["ë¹ˆë„", "ì‹ ë¢°ë„(%)"], ascending=[False, False]).reset_index(drop=True)

                    st.dataframe(conf_df, use_container_width=True)
                else:
                    st.info("OCR í…ìŠ¤íŠ¸ ì¸ì‹ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.info("OCR í…ìŠ¤íŠ¸ ì¸ì‹ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            st.markdown(" ")
            st.markdown("**ê°ì²´/í…ìŠ¤íŠ¸ íŠ¹ì„±**")
            c1, c2 = st.columns([1, 1])
            
            if "peer_avg_dict" not in locals():
                peer_avg_dict = {}

            # ì‹œê°í™” ê³µí†µ ìŠ¤íƒ€ì¼ ê°’
            bar_width = 0.35
            my_color = "#80D2FF"
            peer_color = "#5C6AFF"

            ############################
            # 1. í…ìŠ¤íŠ¸ ìœ„ì¹˜ ë¶„í¬
            ############################
            c1, c2 = st.columns([1, 1])
            with c1:
                text_pos_keys = ["text_left","text_middle","text_right"]
                x_idx = range(len(text_pos_keys))

                my_vals = [int(row.get(k, 0)) for k in text_pos_keys]
                peer_vals = [peer_avg_dict.get(k, 0.0) for k in text_pos_keys]

                fig, ax = plt.subplots()
                ax.bar([i - bar_width/2 for i in x_idx], my_vals, bar_width,
                    label="ë‚´ ì˜ìƒ", color=my_color)
                ax.bar([i + bar_width/2 for i in x_idx], peer_vals, bar_width,
                    label="í‰ê· ", color=peer_color)

                ax.set_xticks(list(x_idx))
                ax.set_xticklabels(["ì™¼ìª½","ì¤‘ì•™","ì˜¤ë¥¸ìª½"])
                ax.set_ylabel("í…ìŠ¤íŠ¸ ë°•ìŠ¤ ìˆ˜")
                ax.set_title("í…ìŠ¤íŠ¸ ìœ„ì¹˜ ë¶„í¬")
                ax.legend()
                st.pyplot(fig)

            ############################
            # 2. í…ìŠ¤íŠ¸ í¬ê¸° ë¶„í¬
            ############################
            with c2:
                text_size_keys = ["text_small","text_medium","text_large"]
                x_idx = range(len(text_size_keys))

                my_vals = [int(row.get(k, 0)) for k in text_size_keys]
                peer_vals = [peer_avg_dict.get(k, 0.0) for k in text_size_keys]

                fig, ax = plt.subplots()
                ax.bar([i - bar_width/2 for i in x_idx], my_vals, bar_width,
                    label="ë‚´ ì˜ìƒ", color=my_color)
                ax.bar([i + bar_width/2 for i in x_idx], peer_vals, bar_width,
                    label="í‰ê· ", color=peer_color)

                ax.set_xticks(list(x_idx))
                ax.set_xticklabels(["ì‘ìŒ","ì¤‘ê°„","í¼"])
                ax.set_ylabel("í…ìŠ¤íŠ¸ ë°•ìŠ¤ ìˆ˜")
                ax.set_title("í…ìŠ¤íŠ¸ í¬ê¸° ë¶„í¬")
                ax.legend()
                st.pyplot(fig)


            ############################
            # 3. ì‚¬ëŒ ìœ„ì¹˜ ë¶„í¬
            ############################
            c3, c4 = st.columns([1, 1])
            with c3:
                person_pos_keys = ["person_left","person_middle","person_right"]
                x_idx = range(len(person_pos_keys))

                my_vals = [int(row.get(k, 0)) for k in person_pos_keys]
                peer_vals = [peer_avg_dict.get(k, 0.0) for k in person_pos_keys]

                fig, ax = plt.subplots()
                ax.bar([i - bar_width/2 for i in x_idx], my_vals, bar_width,
                    label="ë‚´ ì˜ìƒ", color=my_color)
                ax.bar([i + bar_width/2 for i in x_idx], peer_vals, bar_width,
                    label="í‰ê· ", color=peer_color)

                ax.set_xticks(list(x_idx))
                ax.set_xticklabels(["ì™¼ìª½","ì¤‘ì•™","ì˜¤ë¥¸ìª½"])
                ax.set_ylabel("ì‚¬ëŒ ìˆ˜")
                ax.set_title("ì‚¬ëŒ ìœ„ì¹˜ ë¶„í¬")
                ax.legend()
                st.pyplot(fig)

            ############################
            # 4. ì‚¬ëŒ í¬ê¸° ë¶„í¬
            ############################
            with c4:
                person_size_keys = ["person_small","person_medium","person_large"]
                x_idx = range(len(person_size_keys))

                my_vals = [int(row.get(k, 0)) for k in person_size_keys]
                peer_vals = [peer_avg_dict.get(k, 0.0) for k in person_size_keys]

                fig, ax = plt.subplots()
                ax.bar([i - bar_width/2 for i in x_idx], my_vals, bar_width,
                    label="ë‚´ ì˜ìƒ", color=my_color)
                ax.bar([i + bar_width/2 for i in x_idx], peer_vals, bar_width,
                    label="í‰ê· ", color=peer_color)

                ax.set_xticks(list(x_idx))
                ax.set_xticklabels(["ì‘ìŒ","ì¤‘ê°„","í¼"])
                ax.set_ylabel("ì‚¬ëŒ ìˆ˜")
                ax.set_title("ì‚¬ëŒ í¬ê¸° ë¶„í¬")
                ax.legend()
                st.pyplot(fig)
        
        # === í”¼ì–´ ê·¸ë£¹ í‰ê·  í•µì‹¬ ì§€í‘œ í‘œ ===
        with st.expander("ğŸ” í•µì‹¬ ì§€í‘œ ë” ì•Œì•„ë³´ê¸°"):
            if peer_avg_core:
                st.subheader("í•µì‹¬ ì§€í‘œ ë¹„êµ")
                peer_df_show = pd.DataFrame({
                    "ì§€í‘œ": [get_label(k) for k in peer_avg_core.keys()],
                    "ë‚´ ê°’": [row.get(k, np.nan) for k in peer_avg_core.keys()],
                    "í‰ê· ": list(peer_avg_core.values())
                })
                st.dataframe(peer_df_show, use_container_width=True)

       
        # 8) í”¼ì–´ í‰ê· ìœ¼ë¡œ ë§ì¶”ê¸° ì‹œë®¬ë ˆì´ì…˜ (íšŒê·€ëª¨ë¸ + í”¼ì–´ í‰ê· ì´ ìˆì„ ë•Œ)
        if 'reg' in locals() and reg is not None and peer_avg_core:
            st.markdown("---")
            st.header("ğŸ”§ A/B í…ŒìŠ¤íŠ¸")

            # íšŒê·€ ì˜ˆì¸¡ ë„ìš°ë¯¸
            def simulate(modified: dict):
                new_df = df.copy()
                for k, v in modified.items():
                    new_df.at[0, k] = v
                return _predict_views_by_regressor(reg, new_df, feat_cols)

            # ì–´ë–¤ ì§€í‘œë¥¼ ì‹œë®¬í• ì§€ í›„ë³´
            target_keys = [
                'title_length','emoji_count','special_char_count','person_count','has_text',
                'brightness','contrast','word_count','object_count'
            ]

            sims = []
            sims_k = []
            for k in target_keys:
                if k not in peer_avg_core:
                    continue

                cur_val = float(df.iloc[0].get(k, 0))
                peer_val = float(peer_avg_core[k])

                # ì •ìˆ˜í˜•ìœ¼ë¡œ ë³´ëŠ” ê²Œ ìì—°ìŠ¤ëŸ¬ìš´ ì§€í‘œëŠ” ë°˜ì˜¬ë¦¼
                if k in ['emoji_count','special_char_count','person_count','has_text',
                        'word_count','object_count','title_length']:
                    peer_val = int(round(peer_val))

                pred_peer = simulate({k: peer_val})
                diff_val = None
                if predicted_views is not None and pred_peer is not None:
                    diff_val = int(pred_peer) - int(predicted_views)

                sims.append({
                    "ì§€í‘œ": k,
                    "í˜„ì¬ê°’": cur_val,
                    "í‰ê· ê°’": peer_val,
                    "í‰ê· ìœ¼ë¡œ ë§ì¶œ ë•Œ ì˜ˆì¸¡": pred_peer,
                    "ì¦ê°(ì˜ˆì¸¡)": diff_val
                })
                sims_k.append({
                    "ì§€í‘œ": get_label(k),
                    "í˜„ì¬ê°’": cur_val,
                    "í‰ê· ê°’": peer_val,
                    "í‰ê· ìœ¼ë¡œ ë§ì¶œ ë•Œ ì˜ˆì¸¡": pred_peer,
                    "ì¦ê°(ì˜ˆì¸¡)": diff_val
                })


            # ===== [ì¤‘ìš”] ì¦ê°ì´ ì–‘ìˆ˜ì¸ ì• ë“¤ë§Œ ë¬¶ì–´ì„œ í•œë²ˆì— ë°”ê¾¸ë©´? =====
            improving_changes = {}
            for row_sim in sims:
                if row_sim["ì¦ê°(ì˜ˆì¸¡)"] is not None and row_sim["ì¦ê°(ì˜ˆì¸¡)"] > 0:
                    # ì´ ì§€í‘œëŠ” ë°”ê¿€ ê°€ì¹˜ê°€ ìˆìŒ â†’ í”¼ì–´ í‰ê· ê°’ ì‚¬ìš©
                    k = row_sim["ì§€í‘œ"]
                    v = row_sim["í‰ê· ê°’"]
                    improving_changes[k] = v

            if improving_changes:
                pred_combo = simulate(improving_changes)
            else:
                pred_combo = None
                
            # í˜„ì¬ ì˜ˆì¸¡ ì¡°íšŒìˆ˜ì™€ ê°œì„  í›„ ì˜ˆì¸¡ ì¡°íšŒìˆ˜ ê³„ì‚°
            current_pred_views = int(predicted_views) if predicted_views is not None else None
            improved_pred_views = int(pred_combo) if pred_combo is not None else None

            lift_abs = None
            lift_pct = None
            if current_pred_views is not None and improved_pred_views is not None:
                lift_abs = improved_pred_views - current_pred_views
                lift_pct = (lift_abs / current_pred_views) * 100 if current_pred_views > 0 else None

            
            st.markdown(" ")
            st.markdown("### í•µì‹¬ ì„±ê³¼ ìš”ì•½")

            kpi_col1, kpi_col2, kpi_col3 = st.columns(3)

            # ì¹´ë“œ 1: í˜„ì¬ ì˜ˆì¸¡
            kpi_col1.metric(
                label="í˜„ì¬ ì˜ˆìƒ ì¡°íšŒìˆ˜",
                value=(f"{current_pred_views:,}" if current_pred_views is not None else "â€”")
            )

            # ì¹´ë“œ 2: ê°œì„  ì‹œ ì˜ˆìƒ ì¡°íšŒìˆ˜
            kpi_col2.metric(
                label="ê°œì„  í›„ ì˜ˆìƒ ì¡°íšŒìˆ˜",
                value=(f"{improved_pred_views:,}" if improved_pred_views is not None else "â€”"),
                delta=(
                    f"+{lift_abs:,}" if (lift_abs is not None and lift_abs > 0) else None
                )
            )

            # ì¹´ë“œ 3: ì˜ˆìƒ í–¥ìƒë¥ 
            kpi_col3.metric(
                label="í–¥ìƒë¥ (%)",
                value=(f"{lift_pct:.1f}%" if lift_pct is not None else "â€”"),
                delta=(
                    f"+{lift_pct:.1f}%" if (lift_pct is not None and lift_pct > 0) else None
                )
            )
            
    
            st.markdown("### í•µì‹¬ ì§€í‘œë³„ ì¡°ì • ë°©í–¥")
            top_change_rows = (
                pd.DataFrame(sims)
                .dropna(subset=["ì¦ê°(ì˜ˆì¸¡)"])
                .sort_values("ì¦ê°(ì˜ˆì¸¡)", ascending=False)
                .head(3)
            )

            for _, r in top_change_rows.iterrows():
                render_change_row(
                    label   = get_label(r["ì§€í‘œ"]),
                    cur_val = r["í˜„ì¬ê°’"],
                    tgt_val = r["í‰ê· ê°’"],
                    gain    = r["ì¦ê°(ì˜ˆì¸¡)"]
                )
            st.markdown(" ") 
            st.markdown(" ")       
            # ì‹œë®¬ ê²°ê³¼ í‘œ ë³´ì—¬ì£¼ê¸°
            if sims_k:
                st.dataframe(pd.DataFrame(sims_k), use_container_width=True)

                

    except Exception as e:
        st.exception(e)
    finally:
        if tmp_path and os.path.exists(tmp_path):
            try:
                os.remove(tmp_path)
            except Exception:
                pass

